{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provasi Matteo (782922)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consegna\n",
    "<br>\n",
    "<font size=3>\n",
    "\n",
    "Implementare uno script di classificazione basato sul fine tuning di feature neurali, a partire dalle istruzioni viste ad esercitazione.\n",
    "\n",
    "Non è consentito l'uso dello stesso modello visto in laboratorio (ResNet).\n",
    "Utilizzare lo stesso dataset scelto per l'assignment dell'esercitazione 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6zzS26nfuoUe"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "import tarfile\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications import resnet50\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from keras.preprocessing import image as kimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "p5kj-ZpGu1uC",
    "outputId": "4b1e9268-c47e-42b6-bec0-e107cda6ed83"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Model, load_model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import optimizers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yJfxIWVSlrUT"
   },
   "source": [
    "<font size=3>\n",
    "  \n",
    "  <b>!wget</b> è un comando esclusivo di Google Colab che permette di accedere a dei file data unurl."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "iRBq6BV1vCSX",
    "outputId": "5aaff5c2-4b09-49f6-c9f8-cfc882a9096d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-16 13:25:00--  https://www.dropbox.com/s/rpjde5xeflnj7nz/Natural_Images.tar\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.65.1, 2620:100:6021:1::a27d:4101\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.65.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/rpjde5xeflnj7nz/Natural_Images.tar [following]\n",
      "--2019-07-16 13:25:00--  https://www.dropbox.com/s/raw/rpjde5xeflnj7nz/Natural_Images.tar\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc599dc1e55b554df4d3e017b0d6.dl.dropboxusercontent.com/cd/0/inline/AkyAJF6KyAuWPYatzXEhvl-gm7LoDzQUhEzUgeWyvwXDS859JhVNxnQDH9tCcfPex0vSBgehAghJlLucEQAQKUHPreh0rsFLAziLVgm-zT4vqg/file# [following]\n",
      "--2019-07-16 13:25:01--  https://uc599dc1e55b554df4d3e017b0d6.dl.dropboxusercontent.com/cd/0/inline/AkyAJF6KyAuWPYatzXEhvl-gm7LoDzQUhEzUgeWyvwXDS859JhVNxnQDH9tCcfPex0vSBgehAghJlLucEQAQKUHPreh0rsFLAziLVgm-zT4vqg/file\n",
      "Resolving uc599dc1e55b554df4d3e017b0d6.dl.dropboxusercontent.com (uc599dc1e55b554df4d3e017b0d6.dl.dropboxusercontent.com)... 162.125.65.6, 2620:100:6021:6::a27d:4106\n",
      "Connecting to uc599dc1e55b554df4d3e017b0d6.dl.dropboxusercontent.com (uc599dc1e55b554df4d3e017b0d6.dl.dropboxusercontent.com)|162.125.65.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/Akzbo86kPftvz7MCDGEnRM6HoyE2XWe0txf7DAPfD8oZaC-mf6fdzU1DFGWJ_mSHxFw0OfyFjPLOF8U-iDDf4kmuLGwcOSnNF1X1uyEiK5Arx9nwC9VOu3wn5oGGKOW9oK16jIxS25LuzsHNosdBjAosJU1wyA-OcpLZzbBmu8SOi9SH3BUnfihB8Ef3zJul0QgLofX42TDP1UezjZ4HSXWspAZ68Jg5PIDvyumM0XL3DLKgogUdjqJ4gpCTtSjkPlzDjAmqtUbOYAdttUZGYas8EDhDSrtRm0m8609R_gaHoh_qEzXln25ITlJM0LBdwDi0gzBr5BOi3hzFwLxMcvQn/file [following]\n",
      "--2019-07-16 13:25:02--  https://uc599dc1e55b554df4d3e017b0d6.dl.dropboxusercontent.com/cd/0/inline2/Akzbo86kPftvz7MCDGEnRM6HoyE2XWe0txf7DAPfD8oZaC-mf6fdzU1DFGWJ_mSHxFw0OfyFjPLOF8U-iDDf4kmuLGwcOSnNF1X1uyEiK5Arx9nwC9VOu3wn5oGGKOW9oK16jIxS25LuzsHNosdBjAosJU1wyA-OcpLZzbBmu8SOi9SH3BUnfihB8Ef3zJul0QgLofX42TDP1UezjZ4HSXWspAZ68Jg5PIDvyumM0XL3DLKgogUdjqJ4gpCTtSjkPlzDjAmqtUbOYAdttUZGYas8EDhDSrtRm0m8609R_gaHoh_qEzXln25ITlJM0LBdwDi0gzBr5BOi3hzFwLxMcvQn/file\n",
      "Reusing existing connection to uc599dc1e55b554df4d3e017b0d6.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 185020928 (176M) [application/x-tar]\n",
      "Saving to: ‘Natural_Images.tar’\n",
      "\n",
      "Natural_Images.tar  100%[===================>] 176.45M  27.7MB/s    in 6.0s    \n",
      "\n",
      "2019-07-16 13:25:09 (29.5 MB/s) - ‘Natural_Images.tar’ saved [185020928/185020928]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/rpjde5xeflnj7nz/Natural_Images.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ib1StdC-LAw9"
   },
   "source": [
    "<font size=3>\n",
    "\n",
    "Tramite la funzione ``tarfile.open`` si caricano i file presenti nella directory e nella successiva riga li si estraggono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KCc8SzPg4Wxk"
   },
   "outputs": [],
   "source": [
    "tar = tarfile.open('Natural_Images.tar')\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!rm Natural_Images.tar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hKoKOMrXLUFU"
   },
   "source": [
    "<font size=3>\n",
    "    \n",
    "I file da leggere sono dentro a due cartelle che a loro volta sono dentro un'altra cartella. Questa cartella è la directory di base da cui poi saranno caricate le immagini."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TcxqXTbNvIw2"
   },
   "outputs": [],
   "source": [
    "base_path = 'Natural_Images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5USq7QgYLgy9"
   },
   "source": [
    "<font size=3>\n",
    "\n",
    "Con ``ImageDataGenerator`` si definisce il modello da utlizzare e con ``flow_from_directory`` si specificano le modalità con cui trattare le immagini caricate. Come spiegato nell'assignment precedente il modello richiede in ingresso delle immagini con dimensione $299x299$. La <b>batch_size</b> indica il numero di campioni che sono utilizzati per allenare la rete in uno step. La rete sarà costruita a partire da $32$ immagini e si continuerà seguendo campioni di questa grandezza <br>\n",
    "Dato che si ha già a disposizione un test e un train set non è necessario specificare lo split a differenza degli altri assignment. Nel caso si avesse un unico insieme di immagini è possibile utilizzare il parametro <br>validation_split</b> in ``ImageDataGenerator`` per indicare quante immagini devono essere prese come train e quante come test. La stessa funzione viene creata per prendere le immagini del test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "rLDLIlFJvaKv",
    "outputId": "5fb2cc22-5d22-46bc-c77d-a7b966172b14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4829 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Training set\n",
    "train_datagen = kimage.ImageDataGenerator(preprocessing_function=inception_v3.preprocess_input)\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        directory=base_path + 'Train',\n",
    "        target_size=(299, 299),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=32,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=True,\n",
    "        seed=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "2FvaKqXWvf85",
    "outputId": "ccb3e5ce-23f7-4edb-a565-ad35ddc60579"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2070 images belonging to 8 classes.\n"
     ]
    }
   ],
   "source": [
    "# Test set\n",
    "test_datagen = kimage.ImageDataGenerator(preprocessing_function=inception_v3.preprocess_input)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "        directory=base_path + 'Test',\n",
    "        target_size=(299, 299),\n",
    "        color_mode=\"rgb\",\n",
    "        batch_size=1,\n",
    "        class_mode=\"categorical\",\n",
    "        shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECinQX3QNyEe"
   },
   "source": [
    "<font size=3>\n",
    "\n",
    "Si inizia con la creazione di una rete neurale InceptionV3 senza strati fully connected utilizzando un pooling medio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6UJNYd6fvnJE"
   },
   "outputs": [],
   "source": [
    "nn = inception_v3.InceptionV3(include_top=False, weights='imagenet', pooling='avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b3cpn2vUOPJk"
   },
   "source": [
    "<font size=3>\n",
    "\n",
    "Con <b>layer.trainable = False</b> si indica che gli strati della rete non devono essere aggiornati durante il processo di learning in quanto si vuole appunto effettuare un fine-tuning. Vengono aggiunti alla rete due strati:\n",
    "* Uno strato fully connected con $64$ neuroni\n",
    "* Uno strato softmax con il numero di classi del target\n",
    "<br></br>\n",
    "Alla rete viene assegnato una funzione di ottimizzazione e come parametro di loss la <b>categorical_crossentropy</b> in quanto si è in un problema di multi-class in cui l'appartenenza ad una classe è esclusiva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bhdRuJMcyXtS"
   },
   "outputs": [],
   "source": [
    "for layer in nn.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = nn.output\n",
    "x = Dense(64, activation='relu')(x)\n",
    "pred = Dense(8, activation='softmax')(x)\n",
    "\n",
    "net = Model(inputs=nn.input, outputs=pred)\n",
    "net.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEgyslKQRW-j"
   },
   "source": [
    "<font size=3>\n",
    "\n",
    "Con la funzione fit_generator si passa alla rete il generatore che prende le immagini del train e procede con il fine-tuning dei parametri per un numero arbitrario di epoche. Il numero di step da effettuare per ogni epoca deve essere approssimativamente il rapporto $sample/batchsize$. <br>\n",
    "Si effettua un addestramento con $10$ confrontando l'accuracy ad ogni passaggio per vedere quando da un epoca all'altra non ci sono più miglioramenti significativi di accuratezza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 381
    },
    "colab_type": "code",
    "id": "JMBWnWCIFCd9",
    "outputId": "50479094-6d59-492e-e720-6008ff2cbcfd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "151/151 [==============================] - 51s 340ms/step - loss: 0.2881 - acc: 0.9327\n",
      "Epoch 2/10\n",
      "151/151 [==============================] - 47s 314ms/step - loss: 0.0448 - acc: 0.9863\n",
      "Epoch 3/10\n",
      "151/151 [==============================] - 47s 314ms/step - loss: 0.0293 - acc: 0.9905\n",
      "Epoch 4/10\n",
      "151/151 [==============================] - 47s 313ms/step - loss: 0.0187 - acc: 0.9942\n",
      "Epoch 5/10\n",
      "151/151 [==============================] - 47s 313ms/step - loss: 0.0304 - acc: 0.9921\n",
      "Epoch 6/10\n",
      "151/151 [==============================] - 47s 313ms/step - loss: 0.0209 - acc: 0.9934\n",
      "Epoch 7/10\n",
      "151/151 [==============================] - 47s 313ms/step - loss: 0.0185 - acc: 0.9948\n",
      "Epoch 8/10\n",
      "151/151 [==============================] - 47s 313ms/step - loss: 0.0103 - acc: 0.9967\n",
      "Epoch 9/10\n",
      "151/151 [==============================] - 47s 313ms/step - loss: 0.0144 - acc: 0.9948\n",
      "Epoch 10/10\n",
      "151/151 [==============================] - 47s 312ms/step - loss: 0.0128 - acc: 0.9971\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fde27f555f8>"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit_generator(train_generator, steps_per_epoch=151, epochs=10, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VkOF1LC5GoPx",
    "outputId": "81afc4d7-a3fe-4bb3-a3a0-abe235430a4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizione completata in 81.224 secondi\n"
     ]
    }
   ],
   "source": [
    "y_test = test_generator.classes\n",
    "\n",
    "\n",
    "t1 = time()\n",
    "y_dist = net.predict_generator(test_generator, steps=len(test_generator.filenames))\n",
    "y_pred = np.argmax(y_dist, axis=1)\n",
    "print(\"Predizione completata in %0.3f secondi\" % (time() - t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 277
    },
    "colab_type": "code",
    "id": "VhHEQCOcGt6u",
    "outputId": "8046a77f-97d3-4f52-e494-3a9011a368bf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       1.00      1.00      1.00       222\n",
      "         car       1.00      1.00      1.00       274\n",
      "         cat       0.99      1.00      0.99       273\n",
      "         dog       1.00      0.98      0.99       209\n",
      "      flower       1.00      0.99      0.99       275\n",
      "       fruit       0.98      1.00      0.99       299\n",
      "   motorbike       1.00      1.00      1.00       227\n",
      "      person       1.00      1.00      1.00       291\n",
      "\n",
      "    accuracy                           1.00      2070\n",
      "   macro avg       1.00      0.99      1.00      2070\n",
      "weighted avg       1.00      1.00      1.00      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Report\n",
    "target_names = ['airplane', 'car', 'cat', 'dog', 'flower', 'fruit', 'motorbike', 'person']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "etp5Mcg6GxHd",
    "outputId": "560e9a21-30bd-4ba2-8105-d3d6a47fb47e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fde27e96320>"
      ]
     },
     "execution_count": 25,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "juOY4WYyTtg5",
    "outputId": "44877d3f-7f13-4a99-fa94-35d600f4faa9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222   0   0   0   0   0   0   0]\n",
      " [  0 274   0   0   0   0   0   0]\n",
      " [  0   0 272   0   0   1   0   0]\n",
      " [  0   0   3 205   0   1   0   0]\n",
      " [  1   0   0   0 271   3   0   0]\n",
      " [  0   0   0   0   0 299   0   0]\n",
      " [  0   0   0   0   0   0 227   0]\n",
      " [  0   0   0   1   0   0   0 290]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-AQjyWOGTxLW"
   },
   "source": [
    "<font size=3>\n",
    "\n",
    "La performance classificativa è simile a quella del modello del precedente assignment, le osservazioni classificare erroneamente sono $10$ con un'accuratezza complessiva di $0.9951$. La classe <i>dog</i> in questo caso non è la peggiore ma risulta essere <i>fruit</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZGA9Ac1AGPX"
   },
   "source": [
    "## Seconda rete"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_cxsJ_gzAII1"
   },
   "source": [
    "<font size=3>\n",
    "\n",
    "Il modello ottenuto in precedenza con $10$ epoche raggiungeva l'accuratezza massima sul training proprio nell'ultimo passaggio. Questo risultato è stato ottenuto però dopo una serie di alti e bassi indicando che probabilmente il modello si è specializzato troppo sui dati.\n",
    "Osservando i valori ottenuti in precedenza si nota come fino alla quarta epoca l'accuratezza aumenta sistematicamente per poi calare. <br>\n",
    "Si costruisce quindi una seconda rete, uguale alla prima ma addestrata con $4$ epoche; i valori che si otterranno non saranno identici a quella precedente per via della costruzione del modello <b>InceptionV3</b>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "bzPuGlpA0Xk1",
    "outputId": "7b0d2609-7bcd-4b58-d7b0-8e67bd188a14"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0716 13:26:11.369223 139893795407744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "nn2 = inception_v3.InceptionV3(include_top=False, weights='imagenet', pooling='avg')\n",
    "\n",
    "for layer in nn2.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "x = nn2.output\n",
    "x = Dense(64, activation='relu')(x)\n",
    "pred = Dense(8, activation='softmax')(x)\n",
    "\n",
    "net2 = Model(inputs=nn2.input, outputs=pred)\n",
    "net2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 245
    },
    "colab_type": "code",
    "id": "LQTkk3mN0ifs",
    "outputId": "93e35ea3-8c66-4143-b3ec-2de7af023376"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0716 13:26:45.330038 139893795407744 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "151/151 [==============================] - 56s 368ms/step - loss: 0.2812 - acc: 0.9313\n",
      "Epoch 2/4\n",
      "151/151 [==============================] - 47s 312ms/step - loss: 0.0490 - acc: 0.9853\n",
      "Epoch 3/4\n",
      "151/151 [==============================] - 47s 312ms/step - loss: 0.0299 - acc: 0.9909\n",
      "Epoch 4/4\n",
      "151/151 [==============================] - 47s 312ms/step - loss: 0.0181 - acc: 0.9948\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f3aec2dceb8>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net2.fit_generator(train_generator, steps_per_epoch=151, epochs=4, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "VmbEz2Hm0k1Q",
    "outputId": "7bc6691d-3f5d-40a9-a497-c8b007d7f95e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predizione completata in 79.841 secondi\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       1.00      1.00      1.00       222\n",
      "         car       1.00      1.00      1.00       274\n",
      "         cat       0.99      1.00      0.99       273\n",
      "         dog       1.00      0.99      0.99       209\n",
      "      flower       1.00      0.99      0.99       275\n",
      "       fruit       0.99      1.00      1.00       299\n",
      "   motorbike       1.00      1.00      1.00       227\n",
      "      person       1.00      1.00      1.00       291\n",
      "\n",
      "    accuracy                           1.00      2070\n",
      "   macro avg       1.00      1.00      1.00      2070\n",
      "weighted avg       1.00      1.00      1.00      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test = test_generator.classes\n",
    "\n",
    "\n",
    "t1 = time()\n",
    "y_dist = net2.predict_generator(test_generator, steps=len(test_generator.filenames))\n",
    "y_pred = np.argmax(y_dist, axis=1)\n",
    "print(\"Predizione completata in %0.3f secondi\" % (time() - t1))\n",
    "\n",
    "\n",
    "# Report\n",
    "target_names = ['airplane', 'car', 'cat', 'dog', 'flower', 'fruit', 'motorbike', 'person']\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "colab_type": "code",
    "id": "davt-T4o-rvc",
    "outputId": "ad7d0bcc-af0d-4d3d-dc77-14fb627b2edd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f3ae50837f0>"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPgAAAD8CAYAAABaQGkdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrice di confusione\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 156
    },
    "colab_type": "code",
    "id": "HYwMGcZ4-tQ0",
    "outputId": "996bf271-fa3e-4035-f5f4-550d91493615"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[222   0   0   0   0   0   0   0]\n",
      " [  0 274   0   0   0   0   0   0]\n",
      " [  0   0 273   0   0   0   0   0]\n",
      " [  0   0   3 206   0   0   0   0]\n",
      " [  1   0   0   0 271   3   0   0]\n",
      " [  0   0   0   0   0 299   0   0]\n",
      " [  0   0   0   0   0   0 227   0]\n",
      " [  0   0   0   0   0   0   0 291]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Dpmv1fNaA4Xe"
   },
   "source": [
    "<font size=3>\n",
    "\n",
    "L'accuratezza che si ottiene è la stessa identica a quella dell'assignment precedente con $7$ osservazioni classificate in maniera sbagliata. In questa rete le osservazioni sbagliate si concnetrano quasi esclusivamente nelle classi <i>cat</i> e ancora <i>fruit</i>. "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Assignment 4.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
