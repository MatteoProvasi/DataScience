{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provasi Matteo (782922)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Consegna\n",
    "\n",
    "<font size=3>\n",
    "\n",
    "Implementare uno script di classificazione basato sull'estrazione di feature neurali, a partire dalle istruzioni viste ad esercitazione. Non addestrare e testare una rete neurale, ma limitarsi all'uso delle features, con un classificatore esterno. Non è consentito l'uso dello stesso modello visto in laboratorio (ResNet).\n",
    "\n",
    "Selezionare due diversi problemi di classificazione:\n",
    "\n",
    "1. Cani VS gatti (lo stesso dell'esercitazione 4, in modo da evidenziare il miglioramento in performance).\n",
    "2. Problema a scelta (cercare e scaricare un dataset, eventualmente limitandolo in cardinalità)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import joblib\n",
    "import numpy as np\n",
    "import os\n",
    "import sklearn\n",
    "\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage import feature\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "from time import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/path/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Per questo problema classificativo viene scelto InceptionV3, una Convolutional Neural Network svilppata da Google. Nell'immagine che segue è rappresentata la sua architettura.\n",
    "![Architettura InceptionV3](https://miro.medium.com/max/1050/1*gqKM5V-uo2sMFFPDS84yJw.png)\n",
    "<br></br>\n",
    "\n",
    "Il nome <i>V3</i> indica che è la terza versione di questo modello, in particolare i miglioramenti che sono stati apportati rispetto alle versioni precedenti riguardano la fattorizzazione delle convoluzioni: in questo modello si applicano più convoluzioni però di dimensione inferiore, in questo modo gli autori sono riusciti a diminuire il numero di parametri ma a mantenere delle buone performance classificative. Gli elementi che compongono la rete sono:\n",
    "* <b>Convolutional Layer</b>: l'obiettivo di questi layer è quello di estrarre delle features di interesse dalla griglia data in input facendo scorrere una finestra la cui dimensione può variare.\n",
    "* <b>Pooling</b>: sono altri layer per poter estrarre delle features. Sono strumenti di riduzione della dimensionaliltà, restituiscono una griglia con features invarianti per rotazione e posizione. Esistono due tipologie di pooling: \n",
    "    1. <b>Maximum</b>: viene preso il valore massimo della finestra considerata.\n",
    "    2. <b>Average</b>: viene preso il valore medio della finestra considerata.\n",
    "<br></br>\n",
    "<br></br>\n",
    "* <b>Concat</b>: layer di concatenazione che uniscono i valori in input.\n",
    "* <b>Droput</b>: layer che disattiva in maniera randomica dei neuroni all'interno della rete; la ragione principale di questa scelta è per evitare overfitting durante il training.\n",
    "* <b>Fully Connected Layer</b>: posti alla fine della rete prendono in input il risultato degli step precedente e restituisce un vettore di lunghezza pari alla numerosità del target.\n",
    "* <b>Softmax</b>: questa funzione di attivazione prende in input il vettore $n$-dimensioale e modella le probabilità in modo tale che la somma del vettore sia unitaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 41s 0us/step\n"
     ]
    }
   ],
   "source": [
    "nn = inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "La rete neurale scelta è <b>InceptionV3</b>, vengono lasciati i parametri di default con <i>include_top=True</i> che permette l'utilizzo di layer fully-connected e un <i>pooling</i> massimo. <br></br>\n",
    "La seguente funzione per caricare i dati è la stessa dell'assignment precedente, con l'unica differenza che si deve ridimensionare l'immagine in input da passare alla rete neurale. Per costruzione della rete l'immagine deve avere dimensione $299x299$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(feature_extractor, maximages=100):\n",
    "    labels = []\n",
    "    features = []\n",
    "    \n",
    "    for di, d in enumerate(sorted(os.listdir(base_path))):\n",
    "        for fi, f in enumerate(sorted(os.listdir(base_path + d + '/'))):\n",
    "            \n",
    "            if f.endswith('.jpg') and fi < maximages:\n",
    "                image = kimage.load_img(base_path + d + '/' + f, target_size=(299, 299))\n",
    "                cur_features = feature_extractor(image)\n",
    "                features.append(cur_features)\n",
    "                labels.append(di)\n",
    "                \n",
    "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.3, shuffle=True, random_state=0)\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "Dato che le reti neurali di Keras lavorano con batch di immagini è necessario aggiungere una dimensione attraverso <b>np.expand_dims</b>. La funzione <b>preprocess_input</b> serve per adattare la rete neruale alle immagini che saranno caricate dato che è già pre-addestrata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nn_inception(img):\n",
    "    x = kimage.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = inception_v3.preprocess_input(x)\n",
    "    f = nn.predict(x)\n",
    "    return f.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento in 563.796 secondi\n"
     ]
    }
   ],
   "source": [
    "t0 = time()\n",
    "X_train, X_test, y_train, y_test = load_data(feature_extractor=nn_inception, maximages=500)\n",
    "print(\"Caricamento in %0.3f secondi\" %(time() - t0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Come nel precedente assignment viene fatta una normalizzazione e successivamente una grid search per trovare la combinazione ottimale di parametri per la SVC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_stack = np.array([])\n",
    "for t in X_train:\n",
    "    X_train_stack = np.concatenate((X_train_stack, t))\n",
    "eps = 0.001\n",
    "X_train_mean = X_train_stack.mean()\n",
    "X_train_std = X_train_stack.std()\n",
    "X_train = [(t - X_train_mean + eps)/(X_train_std + eps) for t in X_train]\n",
    "X_test = [(t - X_train_mean + eps)/(X_train_std + eps) for t in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addestramento completato in 126.031s\n",
      "Migliore combinazione di parametri:\n",
      " C: 1\n",
      " gamma: 1e-05\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.5, 1, 1.5, 2],\n",
    "              'gamma': [0.00001, 0.0001, 0.001, 0.01]} \n",
    "\n",
    "clf = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=5, n_jobs=1)\n",
    "\n",
    "t1 = time()\n",
    "clf = clf.fit(X_train, y_train)\n",
    "print(\"Addestramento completato in %0.3fs\" % (time() - t1))\n",
    "\n",
    "print(\"Migliore combinazione di parametri:\")\n",
    "print(\" C: \"+ str(clf.best_estimator_.C))\n",
    "print(\" gamma: \"+ str(clf.best_estimator_.gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "La classificazione è quasi ottimale con un'accuratezza del $98$%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report di classificazione:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.98       144\n",
      "           1       0.98      0.99      0.98       156\n",
      "\n",
      "   micro avg       0.98      0.98      0.98       300\n",
      "   macro avg       0.98      0.98      0.98       300\n",
      "weighted avg       0.98      0.98      0.98       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "print(\"Report di classificazione:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Osservando la matrice di classificazione si nota come $3$ gatti sono classificati come cani e $2$ cani sono classificati come gatti, tutte le restanti immagini sono identificate correttamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice di confusione:\n",
      "[[141   3]\n",
      " [  2 154]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x229806fc7b8>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrice di confusione\n",
    "print(\"Matrice di confusione:\")\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n",
    "plt.imshow(cm, cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema a scelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "Per un secondo task di classificazione si è scelto di applicare il classificatore ad un dataset chiamato <i>Natural Images</i> disponibile su [Kaggle](https://www.kaggle.com/prasunroy/natural-images). Il dataset è composto da quasi $7000$ immagini raccolte da diverse fonti, le categorie sono $8$:\n",
    "* Airplanes\n",
    "* Cats\n",
    "* Cars\n",
    "* Dogs\n",
    "* Flowers\n",
    "* Fruits\n",
    "* Motorbikes\n",
    "* Persons\n",
    "<br></br>\n",
    "\n",
    "La numerosità delle classi varia da un minimo di $700$ fino ad un massimo di $1000$. Viene impostata una nuova directory e si seleziona un nuovo upper bound di <i>maximages</i> per caricare tutte le immagini disponibili. <br></br>\n",
    "Seguono gli stessi step eseguiti in precedenza, con la normalizzazione e la grid search dei parametri migliori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = \"C:/path/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Caricamento in 3680.913 secondi\n"
     ]
    }
   ],
   "source": [
    "t2 = time()\n",
    "X2_train, X2_test, y2_train, y2_test = load_data(feature_extractor=nn_inception, maximages=1000)\n",
    "print(\"Caricamento in %0.3f secondi\" %(time() - t2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2_train_stack = np.array([])\n",
    "for t in X2_train:\n",
    "    X2_train_stack = np.concatenate((X2_train_stack, t))\n",
    "eps = 0.001\n",
    "X2_train_mean = X2_train_stack.mean()\n",
    "X2_train_std = X2_train_stack.std()\n",
    "X2_train = [(t - X2_train_mean + eps)/(X2_train_std + eps) for t in X2_train]\n",
    "X2_test = [(t - X2_train_mean + eps)/(X2_train_std + eps) for t in X2_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addestramento completato in 3961.850s\n",
      "Migliore combinazione di parametri:\n",
      " C: 1.5\n",
      " gamma: 0.001\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'C': [0.5, 1, 1.5, 2],\n",
    "              'gamma': [1e-05, 0.0001, 0.001, 0.01]} \n",
    "\n",
    "clf2 = GridSearchCV(SVC(kernel='rbf', class_weight='balanced'), param_grid, cv=5, n_jobs=1)\n",
    "\n",
    "t3 = time()\n",
    "clf2 = clf2.fit(X2_train, y2_train)\n",
    "print(\"Addestramento completato in %0.3fs\" % (time() - t3))\n",
    "\n",
    "print(\"Migliore combinazione di parametri:\")\n",
    "print(\" C: \" + str(clf2.best_estimator_.C))\n",
    "print(\" gamma: \" + str(clf2.best_estimator_.gamma))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "Il modello riesce a classificare con un'elevatissima accuratezza ($0.9966$) le diverse immagini nelle classi. In questo caso, dato che si hanno più classi, viene creata una lista con le labels che saranno visualizzate nel report di classificazione. <br></br>\n",
    "Solamente la classe dei cani non ha un'accuracy perfetta che però si attesta comunque al $0.98$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report di classificazione:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    airplane       1.00      1.00      1.00       222\n",
      "         car       1.00      1.00      1.00       274\n",
      "         cat       1.00      0.99      0.99       273\n",
      "         dog       0.98      1.00      0.99       209\n",
      "      flower       1.00      0.99      1.00       275\n",
      "       fruit       1.00      1.00      1.00       299\n",
      "   motorbike       1.00      1.00      1.00       227\n",
      "      person       1.00      1.00      1.00       291\n",
      "\n",
      "   micro avg       1.00      1.00      1.00      2070\n",
      "   macro avg       1.00      1.00      1.00      2070\n",
      "weighted avg       1.00      1.00      1.00      2070\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['airplane', 'car', 'cat', 'dog', 'flower', 'fruit', 'motorbike', 'person']\n",
    "\n",
    "y2_pred = clf2.predict(X2_test)\n",
    "\n",
    "print(\"Report di classificazione:\")\n",
    "print(classification_report(y2_test, y2_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Dalla matrice si classificazione si può notare come c'è sempre una sola immagine classificata erroneamente per ogni classe, tranne per cani e gatti dove ce ne sono $2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrice di confusione:\n",
      "[[221   0   0   1   0   0   0   0]\n",
      " [  0 274   0   0   0   0   0   0]\n",
      " [  0   0 271   2   0   0   0   0]\n",
      " [  0   0   1 208   0   0   0   0]\n",
      " [  0   0   0   1 273   1   0   0]\n",
      " [  0   0   0   0   0 299   0   0]\n",
      " [  0   0   0   0   0   0 227   0]\n",
      " [  0   0   0   1   0   0   0 290]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x229313c6320>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Matrice di confusione\n",
    "print(\"Matrice di confusione:\")\n",
    "cm2 = confusion_matrix(y2_test, y2_pred)\n",
    "print(cm2)\n",
    "plt.imshow(cm2, cmap=plt.cm.Blues)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
