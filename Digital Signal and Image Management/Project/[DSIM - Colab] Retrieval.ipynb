{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval [Colab]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "Per l'ultimo task di retrieval sono stati utilizzati due notebook, questo è quello relativo allo script effettuato in Colab per ragioni computazionali"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "VnQ9RUrwN_il",
    "outputId": "cd44751e-7767-400c-9e0f-2f8f96ae6643"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import os\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pickle\n",
    "import sklearn\n",
    "import tarfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "from keras.preprocessing import image as kimage\n",
    "from keras.applications import inception_v3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from skimage import feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yRIMR9QOCxB"
   },
   "outputs": [],
   "source": [
    "def load_data(feature_extractor, base_path, maximages):\n",
    "    paths = []\n",
    "    features = []\n",
    "    \n",
    "    for fi,f in enumerate(tqdm(sorted(os.listdir(base_path)))):\n",
    "        if f.endswith('.jpg') and fi < maximages:\n",
    "            # Memorizza percorso file\n",
    "            cur_path = base_path + f\n",
    "            paths.append(cur_path)\n",
    "            \n",
    "            # Carica file ed estraine le features\n",
    "            image = kimage.load_img(cur_path, target_size=(299, 299))\n",
    "            cur_features = feature_extractor(image)\n",
    "            features.append(cur_features)\n",
    "\n",
    "    features = np.array(features)\n",
    "    return features, paths\n",
    "\n",
    "\n",
    "\n",
    "def nn_inception(img):\n",
    "    x = kimage.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    x = inception_v3.preprocess_input(x)\n",
    "    f = nn.predict(x)\n",
    "    return f.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 367
    },
    "colab_type": "code",
    "id": "hQmeMhS8OFvO",
    "outputId": "662a80b6-5f71-41af-ec90-9dd83ec41097"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0718 17:35:43.729918 140532589647744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0718 17:35:43.772158 140532589647744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0718 17:35:43.780449 140532589647744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0718 17:35:43.820990 140532589647744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0718 17:35:43.822299 140532589647744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0718 17:35:46.563218 140532589647744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0718 17:35:46.849091 140532589647744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0718 17:35:47.713143 140532589647744 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.5/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96116736/96112376 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "nn = inception_v3.InceptionV3(include_top=True, weights='imagenet', input_tensor=None, input_shape=None, pooling='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "I primi passaggi sono uguali ai precedenti punti, si parte dal caricamento delle immagini e dall'estrazione delle features mediante la rete neruale <b>InceptionV3</b>. \n",
    "<br></br>\n",
    "Il dataset indicato sull'e-elearning nel progetto d'esame [non è più disponibile](https://www.microsoft.com/en-us/research/project/msra-cfw-data-set-of-celebrity-faces-on-the-web/), è stato quindi scaricato un dataset affine degli stessi autori reperibile a [questo indirizzo](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html). La differenza sostanziale è sul numero di persone presenti, oltre $10000$, mentre per il numero di file presenti la dimensione è pressoché la stessa $205$ mila contro le $202$ mila di quello consigliato.\n",
    "<br></br>\n",
    "\n",
    "I file sono stati caricati un dropbox, caricati ed estratti con i seguenti blocchi di codice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 453
    },
    "colab_type": "code",
    "id": "90Ho9uuDOQ8P",
    "outputId": "5cedc7c6-d07f-4135-877d-f9d628165301"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2019-07-18 17:36:13--  https://www.dropbox.com/s/rhe6vmiulqz7c8z/celebs.tar\n",
      "Resolving www.dropbox.com (www.dropbox.com)... 162.125.82.1, 2620:100:6032:1::a27d:5201\n",
      "Connecting to www.dropbox.com (www.dropbox.com)|162.125.82.1|:443... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: /s/raw/rhe6vmiulqz7c8z/celebs.tar [following]\n",
      "--2019-07-18 17:36:14--  https://www.dropbox.com/s/raw/rhe6vmiulqz7c8z/celebs.tar\n",
      "Reusing existing connection to www.dropbox.com:443.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://uc7aa74bb29d0e763efa2607b4d5.dl.dropboxusercontent.com/cd/0/inline/Ak_rDRHUmPQNwVeK1K9l_6dtBCq9dgojKgmXbFOjCW22cDCsYO5dgrD5E_L5eQYDOolXWdG8ep6uMjGiPBBoyBIEHId0Gfe9pI3DnpiUQ334IA/file# [following]\n",
      "--2019-07-18 17:36:14--  https://uc7aa74bb29d0e763efa2607b4d5.dl.dropboxusercontent.com/cd/0/inline/Ak_rDRHUmPQNwVeK1K9l_6dtBCq9dgojKgmXbFOjCW22cDCsYO5dgrD5E_L5eQYDOolXWdG8ep6uMjGiPBBoyBIEHId0Gfe9pI3DnpiUQ334IA/file\n",
      "Resolving uc7aa74bb29d0e763efa2607b4d5.dl.dropboxusercontent.com (uc7aa74bb29d0e763efa2607b4d5.dl.dropboxusercontent.com)... 162.125.82.6, 2620:100:6032:6::a27d:5206\n",
      "Connecting to uc7aa74bb29d0e763efa2607b4d5.dl.dropboxusercontent.com (uc7aa74bb29d0e763efa2607b4d5.dl.dropboxusercontent.com)|162.125.82.6|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 FOUND\n",
      "Location: /cd/0/inline2/Ak_a8CbqxMNi8ihds8Dabv4WYb35HIDtNAZ7TL_ZrgWuT_fhivEuTCVm_Dh_DoPy4QxhP6h9b6AW9YU-L_T4jnmS45689HBgh16n_n0p7tNoyFAKFH6g12col0awxppBUx7jGP75O7ZB5_TSZcDpfKoQH21ayLWSRji-W5mQLCkCF1Fcq0amVaf1kQ2SSyJXV8VYSL1fAg9g7kJ6PhUtZ_6hfMQFpv5QqGIdXcZni-GphlVAiqytF0VzTwLcvr5SygH14RohBHGOjmk8nCT2dtUGiKP42FKNQ6mMEq360TutR7MEqYBtpgZjgp7Wyxl27Vp-QfNnItJiA7DObxAAlRdT/file [following]\n",
      "--2019-07-18 17:36:15--  https://uc7aa74bb29d0e763efa2607b4d5.dl.dropboxusercontent.com/cd/0/inline2/Ak_a8CbqxMNi8ihds8Dabv4WYb35HIDtNAZ7TL_ZrgWuT_fhivEuTCVm_Dh_DoPy4QxhP6h9b6AW9YU-L_T4jnmS45689HBgh16n_n0p7tNoyFAKFH6g12col0awxppBUx7jGP75O7ZB5_TSZcDpfKoQH21ayLWSRji-W5mQLCkCF1Fcq0amVaf1kQ2SSyJXV8VYSL1fAg9g7kJ6PhUtZ_6hfMQFpv5QqGIdXcZni-GphlVAiqytF0VzTwLcvr5SygH14RohBHGOjmk8nCT2dtUGiKP42FKNQ6mMEq360TutR7MEqYBtpgZjgp7Wyxl27Vp-QfNnItJiA7DObxAAlRdT/file\n",
      "Reusing existing connection to uc7aa74bb29d0e763efa2607b4d5.dl.dropboxusercontent.com:443.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1565297152 (1.5G) [application/x-tar]\n",
      "Saving to: ‘celebs.tar’\n",
      "\n",
      "celebs.tar          100%[===================>]   1.46G  37.5MB/s    in 38s     \n",
      "\n",
      "2019-07-18 17:36:54 (39.0 MB/s) - ‘celebs.tar’ saved [1565297152/1565297152]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://www.dropbox.com/s/rhe6vmiulqz7c8z/celebs.tar\n",
    "\n",
    "tar = tarfile.open('celebs.tar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FHjBAeI_QRy6"
   },
   "outputs": [],
   "source": [
    "tar.extractall()\n",
    "tar.close()\n",
    "\n",
    "base_path = './celebs/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Viene effettuata l'estrazione delle features. Con l'acceleratore di GPU il processo è stato terminato in poco più di due ore, mentre nei notebook sulle nostre macchine il processo effettuava solamente $2$ iterazioni al secondo con un tempo stimato di oltre un giorno, da qui la necessità di utilizzare Colab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "6gc249pTOLH5",
    "outputId": "5aa807f6-c329-48fa-d091-1dba3dbf77bb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 202599/202599 [2:16:57<00:00, 24.66it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, paths = load_data(feature_extractor=nn_inception, base_path=base_path, maximages=1000000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La parte finale dello script è per il salvataggio dei file riguardanti le feature estratte e i percorsi delle immagini relative (questa lista è necessaria per stampare a video le immagini nell'altro notebook) su Colab e il successivo download in locale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 124
    },
    "colab_type": "code",
    "id": "wZ0r02iSXyAD",
    "outputId": "5f626903-cae1-4394-a92d-f81f0fedb584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
      "\n",
      "Enter your authorization code:\n",
      "··········\n",
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n1g7Xe0w7Z3u"
   },
   "outputs": [],
   "source": [
    "np.save('Xtrain.npy', X_train_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZwcJ0l7zRCG1"
   },
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "files.download('Xtrain.npy') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZjODGx5dQ7SP"
   },
   "outputs": [],
   "source": [
    "with open('paths_list', 'wb') as fp:\n",
    "    pickle.dump(paths, fp)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Progetto Retrieval.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
