{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import imblearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import os\n",
    "import re\n",
    "import sklearn\n",
    "\n",
    "import matplotlib.colors\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from imblearn.pipeline import make_pipeline\n",
    "from imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\n",
    "\n",
    "from collections import Counter\n",
    "from gensim.models import KeyedVectors, Word2Vec\n",
    "from gensim.models.callbacks import CallbackAny2Vec\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn import model_selection, naive_bayes, metrics, ensemble\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix, make_scorer, accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from iteration_utilities import deepflatten\n",
    "\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop = set(stopwords.words('english'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "os.chdir('D:\\Scraping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "# [1. Assegnazione delle classi](#1)\n",
    "<br></br>\n",
    "<font size=3>\n",
    "    \n",
    "L'obiettivo di questa prima parte di codice è di assegnare ai pattern relativi un label che sarà il target della classificazione. Per fare ciò si prendono le parole classificate mediante la cluster analysis e i loro sinonimi, parallelamente si uniscono le informazioni del dataset iniziale con i nomi degli attori. \n",
    "\n",
    "Per ogni pattern si controlla se le parole al suo interno sono fra i mille termini più frequenti (o nei sinonimi) individuati durante la cluster analysis. Se un termine è individuato, viene assegnata un etichetta e alla fine del pattern si controlla quale sia l'etichetta più frequente togliendo le etichette assegnate alle parole che non sono fra le più frequenti. Il pattern è quindi classificato con l'etichetta più frequente al suo interno, in caso di parità si premia l'etichetta con il termine meno frequente. Nel caso in cui tutte le parole non siano fra le più frequenti, il pattern viene assegnato ad una nuova etichetta. In ogni pattern si controllano se sono presenti i nomi degli attori, sfruttando il fatto che i due dataset hanno stessa lunghezza e si può fare corrispondenza mediante un indice. In caso affermativo viene creata una nuova etichetta per gli attori.\n",
    "<br></br>\n",
    "<br></br>\n",
    "## [1.1 Dataset](#1.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "I dataset caricati per questo notebook sono:\n",
    "* `imdb_df4`: era l'ultimo creato nel notebook del pre-processing, al suo interno sono contenute le informazioni sul titolo del film, lo score e le recensioni già divide in frasi.\n",
    "* `diz_simiarity`: dizionario con i sinonimi ricavati tramite la matrice di similarità con l'approccio su `Wordnet`. Ad ogni parola, elemento chiave, corrisponde una lista si sinonimi, parole che avevano massima similarità con la chiave.\n",
    "* `w_pattern`: anch'esso ottenuto nel precedente notebook è una lista in cui al suo interno sono presenti i pattern (di parole) significativi identificati nelle frasi delle recensioni.\n",
    "* `labels_df simlified`: è il file `.csv` con le parole, la loro frequenza e il cluster di appartenenza. È stato modificato per fare in modo che le classi meno numerose siano raggruppate insieme ad altre.\n",
    "* `imdb_info`: ottenuto nel processo di scraping, contiene le informazioni sui film, la più importante è il nome degli attori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 30.9 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# dataframe\n",
    "with open('imdb_df4', \"rb\") as input_file:\n",
    "    imdb_df = pickle.load(input_file)\n",
    "    \n",
    "with open(\"diz_similarity\", \"rb\") as input_file:\n",
    "    diz_similarity = pickle.load(input_file)\n",
    "    \n",
    "with open('w_pattern', \"rb\") as input_file:\n",
    "    words = pickle.load(input_file)\n",
    "\n",
    "labels = pd.read_csv('labels_df simplified.csv', delimiter=\";\")\n",
    "info = pd.read_csv(\"imdb_info.csv\", delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Dal dataset delle etichette si aggiunge la lista di sinonimi alla rispettive parole tramite la funzione `map`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "      <th>Freq</th>\n",
       "      <th>Synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>way</td>\n",
       "      <td>0</td>\n",
       "      <td>68935</td>\n",
       "      <td>[manner, style, fashion, mode]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>life</td>\n",
       "      <td>0</td>\n",
       "      <td>61168</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>thing</td>\n",
       "      <td>0</td>\n",
       "      <td>60468</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>love</td>\n",
       "      <td>0</td>\n",
       "      <td>29193</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>problem</td>\n",
       "      <td>0</td>\n",
       "      <td>16458</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Label   Freq                        Synonyms\n",
       "0      way      0  68935  [manner, style, fashion, mode]\n",
       "1     life      0  61168                              []\n",
       "2    thing      0  60468                              []\n",
       "3     love      0  29193                              []\n",
       "4  problem      0  16458                              []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[\"Synonyms\"] = labels[\"Word\"].map(diz_similarity)\n",
    "\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "Da questo dataset sono creati due dizionari, `diz_cluster` e `diz_freq`: il primo avrà come chiave una delle parole più frequenti e come valore la classe di appartenenza, nel secondo la chiave c'è la stessa chiave e il valore è la frequenza. Questo stesso procedimento è realizzato inseriendo anche i sinonimi dove in questo caso la frequenza è assegnata in base alla parola di riferimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_cluster = {}\n",
    "diz_freq = {}\n",
    "for i in range(len(labels)):\n",
    "    \n",
    "    if labels[\"Word\"].iloc[i] not in diz_cluster.keys():\n",
    "        diz_cluster[labels[\"Word\"].iloc[i]] = labels[\"Label\"].iloc[i]\n",
    "        diz_freq[labels[\"Word\"].iloc[i]] = labels[\"Freq\"].iloc[i]\n",
    "    try:  \n",
    "        if len(labels[\"Synonyms\"].iloc[i]) > 0:\n",
    "            for word in labels[\"Synonyms\"].iloc[i]:\n",
    "                if word not in diz_cluster.keys():\n",
    "                    diz_cluster[word] = labels[\"Label\"].iloc[i]\n",
    "                    diz_freq[word] = labels[\"Freq\"].iloc[i]\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Per il dataset sulle informazioni degli attori è necessario effettuare un pre-processing in quanto salvando delle liste in un dataframe e il tutto come `.csv`, una volta caricati, gli elementi sono sempre considerati come stringhe e non come gli oggetti che erano realmente. Attraverso una regular expression della libreria `re` si ricrea una lista di attori per ogni film utilizzando la virgola come carattere separatore degli elementi e rimuovendo la punteggiatura. I risultati sono inseriti nel dizionario `diz_actor` in cui la chiave è il titolo del film e il valore una lista degli attori protagonisti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "diz_actor = {}\n",
    "for i in range(len(info)):\n",
    "    temp = list(info[\"Actor\"].iloc[i].split(\",\"))\n",
    "    actors = [re.sub(r'[^\\w\\s]', '', temp[i].strip(\" \")) for i in range(len(temp))]\n",
    "    title = (info[\"Title\"].iloc[i])\n",
    "    diz_actor[title] = actors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La colonna con i titoli dei film nel dataset delle recensioni viene trasformata in una lista. Sempre attraverso la funzione `map` si assegna ad ogni titolo la lista degli attori protagonisti (la funzione richiede che l'oggetto messo come argomento sia un dizionario)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Le Mans '66 - La grande sfida (2019)</td>\n",
       "      <td>[Matt Damon, Christian Bale, Jon Bernthal, Cai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Le Mans '66 - La grande sfida (2019)</td>\n",
       "      <td>[Matt Damon, Christian Bale, Jon Bernthal, Cai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Le Mans '66 - La grande sfida (2019)</td>\n",
       "      <td>[Matt Damon, Christian Bale, Jon Bernthal, Cai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>Le Mans '66 - La grande sfida (2019)</td>\n",
       "      <td>[Matt Damon, Christian Bale, Jon Bernthal, Cai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Le Mans '66 - La grande sfida (2019)</td>\n",
       "      <td>[Matt Damon, Christian Bale, Jon Bernthal, Cai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784254</td>\n",
       "      <td>Il ritorno di Casanova (1992)</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784255</td>\n",
       "      <td>Amici per la vita (1992)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784256</td>\n",
       "      <td>Amici per la vita (1992)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784257</td>\n",
       "      <td>Amici per la vita (1992)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>784258</td>\n",
       "      <td>Amici per la vita (1992)</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>784259 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Title  \\\n",
       "0       Le Mans '66 - La grande sfida (2019)   \n",
       "1       Le Mans '66 - La grande sfida (2019)   \n",
       "2       Le Mans '66 - La grande sfida (2019)   \n",
       "3       Le Mans '66 - La grande sfida (2019)   \n",
       "4       Le Mans '66 - La grande sfida (2019)   \n",
       "...                                      ...   \n",
       "784254         Il ritorno di Casanova (1992)   \n",
       "784255              Amici per la vita (1992)   \n",
       "784256              Amici per la vita (1992)   \n",
       "784257              Amici per la vita (1992)   \n",
       "784258              Amici per la vita (1992)   \n",
       "\n",
       "                                                   Actors  \n",
       "0       [Matt Damon, Christian Bale, Jon Bernthal, Cai...  \n",
       "1       [Matt Damon, Christian Bale, Jon Bernthal, Cai...  \n",
       "2       [Matt Damon, Christian Bale, Jon Bernthal, Cai...  \n",
       "3       [Matt Damon, Christian Bale, Jon Bernthal, Cai...  \n",
       "4       [Matt Damon, Christian Bale, Jon Bernthal, Cai...  \n",
       "...                                                   ...  \n",
       "784254                                                NaN  \n",
       "784255                                                 []  \n",
       "784256                                                 []  \n",
       "784257                                                 []  \n",
       "784258                                                 []  \n",
       "\n",
       "[784259 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_title_list = list(imdb_df[\"Title\"])\n",
    "new_df = pd.DataFrame({\"Title\":df_title_list})\n",
    "new_df[\"Actors\"] = new_df[\"Title\"].map(diz_actor)\n",
    "new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [1.2 Assegnazione](#1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "In questo passaggio verraano assegnate le etichette ad ogni pattern rilevante, tenendo presente non solo le informazioni ottenute tramite la cluster analysis, ma anche informazioni esterne ottenute in altri passaggi come il nome degli attori. La prima riga di codice è creare una lista con gli attori presenti in ogni film, ricavato nel passaggio precedente. Questa lista contiene dei duplicati in quanto il riferimento è la singola recensione e non un titolo univoco di film, ma mantenendo questo ordine è possibile far corrispondere questa lista a quella dei pattern rilevanti in quanto la lunghezza dei due oggetti è la stessa, $784259$ elementi, la lunghezza del dataframe originale creato mediante scraping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "actors_list = list(new_df[\"Actors\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La seguente funzione di effettuare l'assegnazione. I passaggi sono:\n",
    "* Creazione di una lista in cui saranno salvate le classi assegnate, `category_list`. Si itera all'interno della lista dei pattern:\n",
    "    * In ogni elemento è presente una lista con i pattern rilevanti di ogni frase. Sono create delle liste temporanee dove saranno salvate le etichette e delle variabili di controllo, `check` e `max_freq`.\n",
    "        * Si itera all'interno di ogni lista di pattern rilevanti di frasi in quanto è possibile che una singola frase abbia più pattern rilevanti al suo interno, dunque più elementi e quindi la lista era il formato più comodo per salvare questa informazione. \n",
    "        * Se la lunghezza del topic non è nulla, quindi esiste almeno un pattern rilevante per quella frase, si controlla se nella lista degli attori di quel film (ricavabile tramite l'indice della recensione), almeno uno compare nel testo. In caso positivo lo si segnala con una variabile, `actor_value`, altrimenti si procede,\n",
    "        * Per ogni parola nel pattern rilevanti si controlla quale sia l'eventuale cluster di appartenenza, in caso di assenza fra i termini più comuni si assegna il valore $-1$. Si controlla anche la frequenza delle parole di cui viene presa la minima e la classe di riferimento.\n",
    "        * Ci crea una lista escludendo i valori negativi delle parole non trovate e si effettua un conteggio delle etichette più frequenti:\n",
    "            * Se la classe più numerosa è unica e non ci sono attori nel pattern, tutto quel pattern avrà come etichetta quello della classe più comune.\n",
    "            * Se ci sono più classi con la stessa frequenza si premia quella della parola con la frequenza minore (più rara), in modo da non sfavorire i termini meno comuni.\n",
    "            * Se è presente almeno un attore nel pattern, il pattern è contrassegnato con una nuova etichetta che rappresenta la classe degli attori.\n",
    "\n",
    "I risultati sono salvati in una lista per ogni frase e in un'altra lista per ogni recensione. Il risultato finale sarà una lista con tanti elementi quante erano le recensioni originarie e all'interno di ogni elemento una lista con la classe relativa al pattern identificato."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:49<00:00, 7176.60it/s]\n"
     ]
    }
   ],
   "source": [
    "category_list = []\n",
    "temp = []\n",
    "for k in tqdm(range(len(words))): # si itera per ogni recensione\n",
    "    sentence_list = []\n",
    "    \n",
    "    for sentence in words[k]: # si itera per ogni frase nella recensione\n",
    "        temp_list = []\n",
    "        temp_list2 = []\n",
    "        check = -1\n",
    "        max_freq = 1000000\n",
    "        \n",
    "        for topic in sentence: # si itera per ogni pattern rilevante nella recensione\n",
    "            actor_value = 0\n",
    "            \n",
    "            # si controlla se la lunghezza è nulla o ci siano nomi di attori\n",
    "            if len(topic) == 0:\n",
    "                temp_list2.append('')\n",
    "                break\n",
    "            if (type(actors_list[k]) == list) and (len(actors_list[k]) > 0):\n",
    "                for actor in actors_list[k]:\n",
    "                    if actor in topic:\n",
    "                        if len(actor) > 3:\n",
    "                            temp.append(str(k) + \"\\t \" + actor + \"\\t \"  + topic[0:int(len(topic)/3)])\n",
    "                            actor_value = 1\n",
    "                        \n",
    "            # si itera per ogni parola nel pattern rilevante per identificarne l'appartenenza ad un cluster            \n",
    "            w = topic.split(\" \")\n",
    "            for word in w:\n",
    "                category = -1\n",
    "                if word in diz_cluster.keys():\n",
    "                    category = diz_cluster[word]\n",
    "                    freq = diz_freq[word]\n",
    "                    if freq < max_freq:\n",
    "                        max_freq = freq\n",
    "                        check = category\n",
    "                \n",
    "                temp_list.append(category)\n",
    "                \n",
    "            # si assegna al pattern la classe più frequente nelle sue parole\n",
    "            temp_list = [el for el in temp_list if el != -1]\n",
    "            mc = Counter(temp_list).most_common()\n",
    "            if len(mc) > 0 and actor_value == 0:\n",
    "                if mc[0][0] != mc[0][1]:\n",
    "                    temp_list2.append(mc[0][0])\n",
    "                else:\n",
    "                    for i in range(len(mc)):\n",
    "                        if mc[i][0] == check:\n",
    "                            temp_list2.append(mc[i][0])\n",
    "                            break\n",
    "            elif len(mc) == 0 and actor_value == 0:\n",
    "                temp_list2.append(-1)\n",
    "            elif actor_value == 1:\n",
    "                temp_list2.append(100)\n",
    "        \n",
    "        sentence_list.append(temp_list2)\n",
    "    category_list.append(sentence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "I pattern con etichetta $-1$ sono stati considerati, rappresentano un nuovo cluster in cui non sono presenti dei termini molto frequenti e saranno la classe degli elementi generali. Sono però rimossi gli elementi nulli, ovvero quelli relativi a quelle frasi dove non è stato riscontrato nessun pattern rilevante, questo viene realizzato sia per le etichette che per le parole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14149712 14149712\n",
      "Wall time: 34.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = [el for el in list(deepflatten(category_list, depth=2)) if el != '']\n",
    "test2 = [el for el in list(deepflatten(words, depth=2)) if el != '']\n",
    "print(len(test), len(test2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Da queste liste si crea un dataset dove la colonna `Topic` rappresenta il pattern di interesse e la colonna `Label` la classe di riferimento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Amazing chemistry</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>seamless CGI</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>practical effects</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>film a firecracker script a true</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>story pulse pounding soundtrack booming</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149707</td>\n",
       "      <td>girl who spent the entire</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149708</td>\n",
       "      <td>Everyone around her constantly bent</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149709</td>\n",
       "      <td>little snot</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149710</td>\n",
       "      <td>little brat</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149711</td>\n",
       "      <td>good movie</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14149712 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Topic  Label\n",
       "0                               Amazing chemistry      4\n",
       "1                                    seamless CGI      4\n",
       "2                               practical effects      4\n",
       "3                film a firecracker script a true      4\n",
       "4         story pulse pounding soundtrack booming      8\n",
       "...                                           ...    ...\n",
       "14149707                girl who spent the entire      6\n",
       "14149708      Everyone around her constantly bent     -1\n",
       "14149709                              little snot     -1\n",
       "14149710                              little brat     -1\n",
       "14149711                               good movie     10\n",
       "\n",
       "[14149712 rows x 2 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern_labels = pd.DataFrame({\"Topic\":test2, \"Label\":test})\n",
    "pattern_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pattern_labels\", \"wb\") as output_file:\n",
    "    pickle.dump(pattern_labels, output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pattern_labels\", \"rb\") as read_file:\n",
    "    pattern_labels = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "# [2. Modelli di classificazione](#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Tramite la funzione `train_test_split` di `sklearn` si ricavano il train e il test del dataset. Nelle variabili il cui nome inizia per \"<b>X</b>\" sono presenti i pattern di train e di test, nella variabili che iniziano per \"<b>y</b>\" le etichette di train e di test. Per replicare i risultati e confrontare diveri modelli viene impostato un random seed e la tecnica per scegliere quali osservazioni rientrano nel test o nel train segue l'approccio di stratificazione, ovvero le proporzioni di etichette presenti nel dataset completo si rispecchieranno anche all'interno del train e del test. Non specificando la dimensione del train e del test si applicano i valori di default $70\\%$ e $30\\%$.\n",
    "\n",
    "Per applicare una corretta classificazione è necessario trasformare il testo in un oggetto che sia comprensibile ai modelli. La soluzione per cui si è optato è quella del <b>TF-IDF</b> (<i>Term frequency - Inverse document frequency</i>), una metrica che esprime l'importanza di termine in un documento relativamente ad un corpus di documenti. La funzione è composta da due parti: una è la frequenza del termine e l'altra è la frequenza inversa all'interno dei documenti. Lo scopo di questa metrica è premiare le parole frequenti globalmente nel corpus ma presenti in pochi documenti. Esistono diversi metodi per calcolare questa metrica, in `sklearn` la formula utilizzata per il <b>TF-IDF</b> dato un termine $t$ e un documento $d$ è:\n",
    "$$ TFIDF_{(t,d)} = tf{(t,d)} \\times idf{(t)} $$\n",
    "\n",
    "Dove $tf{(t,d)}$ è il numero di volte che compare il termine $t$ nel documento $d$ e l'altra quantità è pari a: $idf{(t)} = log{\\frac{n}{df(t)}}$ con $n$ il numero totale di documenti.\n",
    "\n",
    "Il primo step è inizializzare questa funzione mediante `TfidfVectorizer` i parametri che riceve in ingresso sono:\n",
    "* `analyzer`: la tipologia utilizzata per analizzare il testo, in questo caso si seleziona a livello di parola ma è possibile analizzare anche n-grammi.\n",
    "* `token_pattern`: espressione regolare per definire cosa sia un token. In questo caso a tutte le parole sono rimossi gli elementi di punteggiatura o alfanumerici `\\w` di lunghezza pari a uno o superiore `{1,}`.\n",
    "* `max_features`: il numero di termini da considerare, nel caso ci siano più termini di quelli massimi, si selezionano i più frequenti. Effettuare una analisi con termini rari, anche se si lavoro con una metrica particolare, i risultati possono risentirne in alcuni casi, fissando un limite ragionevole si possono ottenere delle discrete performance.\n",
    "\n",
    "Il secondo passaggio è quello di centrare/normalizzare i dati togliendo una media comune $\\mu$ e dividendo per una variazione $\\sigma$. Questi passaggi sono possibili mediante la funzione `fit_transform` che può essere applicata direttamente alla funzione TF-IDF mettendo come input il vettore dei pattern di train. Per i dati di test i valori con cui sono centrati i dati devono essere gli stessi, non si deve riapplicare l'intera funzione ma è sufficiente il metodo `transform`. La funzione `fit_transform` unisce sia la funzione `fit` per salvare i due parametri e `transform` per applicare la trasformazione, richiamando solo il secondo la trasformazione viene realizzata correttamente in quanto i valori sono già stati creati e salvati da `fit_transform` sul train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pattern_labels[\"Topic\"], pattern_labels[\"Label\"], \n",
    "                                                    stratify = pattern_labels[\"Label\"], random_state = 0)\n",
    "\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=20000)\n",
    "xtrain_tfidf =  tfidf_vect.fit_transform(X_train)\n",
    "xtest_tfidf =  tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Per la matrice di errata classificatione viene definita una nuova scala di colori, totalmente incentrata sul rosso. Come primo passaggio si definisce il range di valori, $[-1,1]$, successivamente una lista di tonalità in corrispondenza di un valore all'interno del range. Con la funzione `LinearSegmentedColormap.from_list` è possibile ridefinire un colore in base ad una lista di valori creati dall'utente. In questo caso si crea un nuovo oggetto che non sostituisce nessuno già esistente ma che presenta la nuova scala di valori."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm = matplotlib.colors.Normalize(-1,1)\n",
    "colors = [[norm(-1.0), \"lightyellow\"],\n",
    "          [norm(-0.95), \"antiquewhite\"],\n",
    "          [norm(-0.8), \"wheat\"],\n",
    "          [norm(-0.3), \"navajowhite\"],\n",
    "          [norm( 0.3), \"orange\"],\n",
    "          [norm( 0.8), \"tomato\"],\n",
    "          [norm( 0.9), \"red\"],\n",
    "          [norm( 1.0), \"darkred\"]]\n",
    "\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list(\"\", colors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "La funzione `train_model` permette di applicare un metodo di classificazione e di visualizzarne i risultati. I parametri in input sono:\n",
    "* `classifier`: un metodo di classificatione.\n",
    "* `feature_vector_train`: un vettore con i dati di train.\n",
    "* `label`: un vettore con le etichette relative alle osservazioni del train.\n",
    "* `feature_vector_valid`: un vettore con i dati di test.\n",
    "* `method`: stringa con il nome del metodo, serve solamente per il print dei risultati.\n",
    "\n",
    "In questa funzione il classificatore prende in input il vettore dei dati e delle etichette di test e lo si allena con la funzione `fit`. A questo classificatore addestrato viene applicata la funzione `predict` che restituisce come output un vettore di etichette relative al vettore di test dato in input.\n",
    "\n",
    "Si stampa il report di classificazione comparando il vettore delle etichette di test e il vettore delle etichette prodotto dal modello. Da esso si ricava anche la matrice di confusione.\n",
    "\n",
    "Per la visualizzazione della matrice si utilizza `matplotlib` per creare l'oggetto e la matrice viene scalata in base ai valori di riga, in modo tale da visualizzare le percentuali e non il numero totale di osservazioni, così facendo la scala di colori definita in precedenza sarà coerente con la proporzione di osservazioni all'interno di ogni cella e non sul numero totale (che non è indicativo delle performance in quanto le classi non sono bilanciate e celle più numerose non corrispondono necessariamente a classificazioni migliori). Si ricava infine il valore di accuratezza che è messo come output della funzione."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(classifier, feature_vector_train, label, feature_vector_valid, method):\n",
    "    \n",
    "    # train classification\n",
    "    classifier.fit(feature_vector_train, label)\n",
    "    \n",
    "    # prediction on test\n",
    "    predictions = classifier.predict(feature_vector_valid)\n",
    "    \n",
    "    # report\n",
    "    print(classification_report(y_test, predictions))\n",
    "    \n",
    "    # confusion matrix\n",
    "    cm = confusion_matrix(predictions, y_test)\n",
    "    print(cm)\n",
    "    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    fig = plt.figure(figsize = (8, 8))\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(cm, cmap=cmap)\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    plt.title('Confusion matrix of ' + method, pad=40)\n",
    "    #ax.set_xticklabels([''] + shortfilename, rotation=45)\n",
    "    #ax.set_yticklabels([''] + shortfilename)\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.show()\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [2.1 Naive Bayes](#2.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Utilizza il teorema di Bayes per stimare le probabilità di appartenenza di un'osservazione ad una determinata classe; è uno dei metodi più utilizzati nella classificazione di testi ed è spesso utilizzato con dei dati rappresentati da un vettore TF-IDF. Per ogni classe $y$ il modello crea un vettore $\\theta_y = (\\theta_{y1}, \\theta_{y2}, \\dots, \\theta_{yn})$ in cui ogni singolo elemento rappresenta la probabilità $P(x_i|y)$ di appartenenza di quel termine alla classe $y$; il vettore ha lunghezza $n$ come il numero di termini dati in input.\n",
    "\n",
    "I valori di probabilità sono stimati mediante una funzione di massima verosimiglianza incentrata sulle frequenze:\n",
    "\n",
    "$$ \\hat{\\theta}_{yi} = \\frac{N_{yi} + \\alpha}{N_y + \\alpha n}$$\n",
    "\n",
    "Dove $N_{yi} = \\sum_{x \\in T}{x_i}$ è il numero di volte che un termine compare in un campione della classe $y$ nel training set $T$ e $N_y = \\sum_{i=1}^{n}{N_{yi}}$ è il numero totale di termini nella classe $y$.\n",
    "\n",
    "Il valore $\\alpha$ è chiamato fattore di smoothing e di default è pari a $1$; serve per gestire i casi in cui nel test set si trovino dei termini non presenti nel train evitando problemi di calcolo o l'assegnazione diretta di probabilità nulle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "<br></br>\n",
    "# [3. GridSearch](#3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La funzione `GridSearchCV` permette di realizzare diverse prove su un modello di classificazione e trovare il migliore al variare dei parametri. Il modello migliore viene selezionato in base ad una metrica scelt in input dall'utente.\n",
    "\n",
    "Il modello selezionato per la <b>GridSearch</b> è il Naive Bayes: anche se è quello con le peggiori performance, è anche il più veloce da allenare e permette quindi di realizzare molte più combinazioni rispetto agli altri modelli. La speranza è che miglioramenti significativi possano rispecchiarsi anche negli altri modelli.\n",
    "\n",
    "I parametri da ricercare sono:\n",
    "* `alpha`: con diversi valori, da un minimo di $1^{-10}$, estremo inferiore per l'algoritmo e un massimo di uno.\n",
    "* `fit_prior`: se il modello deve o meno considerare le probabilità a priori, se è il parametro è falso viene applicata una probabilità a priori uniforme."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = naive_bayes.MultinomialNB()\n",
    "parameters = {\"alpha\":[1e-10, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, 1], \n",
    "              \"fit_prior\":[True, False]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La ricerca effettua tutte le combinazioni possibili dei parametri dati in input precedentemente: nel caso in esame ci sono $8$ parametri per il valore di $\\alpha$ e $2$ per le probabilità a priori per un totale di $8*2=16$ modelli differenti. Gli altri parametri della funzione sono:\n",
    "* `cv`: è il numero di fold di cross-validazione che la funzione applica per rendere i risultati più robusti. Con questo parametro attivo la funzione effettua un ulteriore split sul train in due dataset, valuta attraverso la CV la metrica di ogni fold e ne restituisce la media. Il valore impostato è $3$, ciò significa che il totale di operazioni effettuate dall'algoritmo sarà $16*3=48$.\n",
    "* `verbose`: un valore numerico, più è alto, più informazioni sono stampate a schermo durante il processo di creazione dei modelli.\n",
    "* `n_jobs`: il numero di core da utilizzare dato che l'algoritmo supporta processi in parallelo. Più è alto più core e CPU sarà utilizzata e più velocemente il processo di ricerca terminerà (i tempi non scalano linearmente con il variare dei core selezionati).\n",
    "\n",
    "La ricerca dei modelli è effettuata dopo la creazione del vettore <b>TF-IDF</b>. L'output della ricerca è il modello migliore sul train che poi viene addestrato sui dati di test. È possibile poi ricavare come prima il livello di accuratezza e i parametri che definiscono il modello migliore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    8.0s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   13.2s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   18.6s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   27.4s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   48.1s remaining:    4.3s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   52.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 1e-10, 'fit_prior': True}\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(model, param_grid=parameters, scoring=\"accuracy\", cv=3, verbose=10, n_jobs=5)\n",
    "clf.fit(xtrain_tfidf, y_train)\n",
    "y_pred = clf.predict(xtest_tfidf)\n",
    "print(clf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5522419113548035"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.1 Features](#3.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "La qualità dei modelli ricercati dipende molto anche dai dati che vengono forniti in input, ovvero di come vengono creati i valori di <b>TF-IDF</b>. La funzione `grid` combina diversi parametri per la creazione dei vettori di features, i parametri in input sono:\n",
    "* `features`: il numero di features massime che il modello deve considerare. Nell'esempio in precedenza sono state considerate $20000$ features, questo parametro riceve in input una lista di valori e per ognuno di essi ricava le features più appropriate e su di esse si effettua una ricerca dei modelli migliori.\n",
    "* `model`: il modello in input, in questo caso sempre il Naive Bayes.\n",
    "* `parameters`: anche questo come il precedente è un parametro per la <b>GridSearch</b>.\n",
    "* `analyzer`: la metodologia con la quale le features devono essere considerate, in questi casi parole e non singoli caratteri.\n",
    "* `stop`: se applicare o meno un filtro di stopwords.\n",
    "* `ngram_range`: se considerare gli n-grammi nel processo di creazione delle features. Il valore in input a questo parametro è una tupla dove l'estremo inferiore rappresenta la lunghezza minima degli oggetti e l'estremo superiore la lunghezza massima. Il valore $1$ per entrambi gli estremi indica solamente le parole normali, la combinazione $(2,2)$ indica solo bigrammi, la combinazione $(1,2)$ indica si parole singole che bigrammi contemporaneamente. A seconda di come è impostato questo parametro, il numero di features massime da considerare dovrà adattarsi di conseguenza.\n",
    "* `verbose`: per visualizzare il progresso.\n",
    "\n",
    "In breve la funzione combina la ricerca delle features con la ricerca dei modelli migliori. Per ogni valore di features il modello migliore è salvato in una lista."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(features, model, parameters, analyzer, stop, ngram_range=(1,1), verbose=10):\n",
    "    score_list = []\n",
    "    for feature in features:\n",
    "        tfidf_vect = TfidfVectorizer(analyzer=analyzer, token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                     stop_words=stop, ngram_range=ngram_range)\n",
    "        xtrain_tfidf =  tfidf_vect.fit_transform(X_train)\n",
    "        xtest_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "        clf = GridSearchCV(model, param_grid=parameters, scoring=\"accuracy\", cv=3, verbose=verbose, n_jobs=5)\n",
    "        clf.fit(xtrain_tfidf, y_train)\n",
    "        y_pred = clf.predict(xtest_tfidf)\n",
    "        score_list.append(clf.best_params_)\n",
    "        score_list.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return (score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Questa funzione mostra a schermo i risultati della ricerca. Per ogni valore di feature si è trovato il modello migliore, la funzione mostra i parametri del modello e il livello di accuratezza raggiunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(score_list):\n",
    "    i = 0\n",
    "    while i < len(score_list):\n",
    "        print(\"Parametri: \" + str(score_list[i]) + \"\\tAccuratezza: \" + str(round(score_list[i+1], 4)))\n",
    "        i += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "I parametri in ingresso per la griglia sono gli stessi, le features partono da un minimo molto basso di $1000$ per poi crescere progressivamente fino ad arrivare a tutte le features possibili senza limiti massimi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "features = [1000, 3000, 5000, 10000, 15000, 20000, 50000, None]\n",
    "\n",
    "model = naive_bayes.MultinomialNB()\n",
    "\n",
    "parameters = {\"alpha\":[1e-10, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, 1], \n",
    "              \"fit_prior\":[True, False]}\n",
    "    \n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Un esempio di output dei risultati è il seguente: il modello migliore per $1000$ features ha un $\\alpha$ sostanzialmente nullo e utilizza le probabilità a priori, raggiungendo un livello di accuratezza di $0.5089$. Per ogni riga si ha il modello migliore per ogni valore di features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5089\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5474\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5515\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5524\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5522\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5522\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5504\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5547\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.2 Rimozione stopwords con TfidfVectorizer](#3.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Nelle analisi precedenti non è stato assegnato nessun parametro a `stop`, dunque tutte le parole erano state prese in considerazione per la creazione del vettore di features. Una scelta più saggia è quella di escludere questi termini non indicativi in quanto possono avere dei valori di <b>TF-IDF</b> molto importanti nella logica dell'algoritmo per effettuare la classificazione.\n",
    "<br></br>\n",
    "\n",
    "Il parametro fa riferimento proprio alla creazione del vettore di features e specificando la stringa `english` è possibile filtrare le stopwords inglesi, la rimozione è già implementata nella funzione senza dover specificare una lista esterna, ma bisogna specificare la stringa poiché il parametro di default è nullo (come visto in precedenza).\n",
    "<br></br>\n",
    "\n",
    "Tutti gli altri parametri del modello e della ricerca sono lasciati invariati ad eccezione del numero di features poiché numero molto bassi non portavano a buoni risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   44.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   45.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   44.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   45.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   47.1s finished\n"
     ]
    }
   ],
   "source": [
    "features = [5000, 10000, 15000, 20000, 50000]\n",
    "\n",
    "model = naive_bayes.MultinomialNB()\n",
    "\n",
    "parameters = {\"alpha\":[1e-10, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, 1], \n",
    "              \"fit_prior\":[True, False]}\n",
    "    \n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=\"english\", verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Dai risultati riportati in seguito si nota come non c'è un grande miglioramento nell'accuratezza, e i migliori modelli hanno pressoché le stesse performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5529\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5541\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5541\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5537\n",
      "Parametri: {'alpha': 0.2, 'fit_prior': True}\tAccuratezza: 0.5516\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.3 Rimozione stopwords con NLTK](#3.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La lista di stopwords utilizzate nel pacchetto sklearn, ricavabile con `sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS` non è necessariamente uguale a quella di `nltk`, inizializzata durante l'import delle librerie all'inizio del notebook con `stop = set(stopwords.words(\"english\"))`. \n",
    "<br></br>\n",
    "\n",
    "Si verifica se l'utilizzo di un diverso set di stopwords può migliorare le performance. A differenza del metodo precedente, qua la rimozione deve essere effettuata prima delle creazione del dataset. Quando si selezionano i pattern rilevanti, scartando quelli vuoti, si filtrano anche le stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 37.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "test = [el for el in list(deepflatten(category_list, depth=2)) if el != '']\n",
    "test2 = [el for el in list(deepflatten(words, depth=2)) if el != '']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La funzione sw_rem prende in input una lista di termini e ad uno ad uno controlla che non siano presenti nella lista delle stopword. Si ricrea una stringa per ogni pattern inserendo le parole adeguate seguite da uno spazio; quando questa stringa viene aggiunta alla lista in output, l'ultimo spazio bianco viene rimosso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sw_rem(word_list):\n",
    "    new_test = []\n",
    "    for pattern in word_list:\n",
    "        new_pattern = \"\"\n",
    "        pattern = pattern.split(\" \")\n",
    "        for word in pattern:\n",
    "            if word not in stop:\n",
    "                new_pattern = new_pattern + word + \" \"\n",
    "        new_test.append(new_pattern[:-1])\n",
    "    \n",
    "    return(new_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La lista senza stopword diventa la nuova colonna del dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14149712 14149712\n"
     ]
    }
   ],
   "source": [
    "new_test = sw_rem(test2)\n",
    "print(len(test), len(new_test))\n",
    "\n",
    "pattern_labels = pd.DataFrame({\"Topic\":new_test, \"Label\":test})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Di conseguenza si deve ricavare un nuovo split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pattern_labels[\"Topic\"], pattern_labels[\"Label\"], \n",
    "                                                    stratify = pattern_labels[\"Label\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   45.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   44.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   45.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   45.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   47.8s finished\n"
     ]
    }
   ],
   "source": [
    "features = [5000, 10000, 15000, 20000, 50000]\n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5647\n",
      "Parametri: {'alpha': 0.1, 'fit_prior': True}\tAccuratezza: 0.5652\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5649\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5643\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5619\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.4 Rimozione stopwords mista](#3.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Avendo confermato che le due liste di stopwords sono differenti, si prova una classificazione con entrambe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   16.2s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   26.0s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   36.1s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   47.4s remaining:    4.2s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   51.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   16.4s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   37.4s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   48.5s remaining:    4.3s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   52.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   10.2s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   15.0s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   24.9s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   33.7s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   43.4s remaining:    3.9s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   46.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   10.3s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   15.3s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   24.5s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   34.1s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   44.2s remaining:    3.9s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   47.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.2s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    9.9s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   14.8s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   23.9s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   33.2s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   43.1s remaining:    3.8s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   47.0s finished\n"
     ]
    }
   ],
   "source": [
    "features = [5000, 10000, 15000, 20000, 50000]\n",
    "\n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 0.1, 'fit_prior': True}\tAccuratezza: 0.5535\n",
      "Parametri: {'alpha': 0.1, 'fit_prior': True}\tAccuratezza: 0.5545\n",
      "Parametri: {'alpha': 0.1, 'fit_prior': True}\tAccuratezza: 0.5546\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5543\n",
      "Parametri: {'alpha': 0.2, 'fit_prior': True}\tAccuratezza: 0.5522\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.5 Bigrammi](#3.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Una tecnica che dovrebbe effettivamente migliorare le performance del modello è quella di considerare n-grammi. La rappresentazione di una parola affiancata ad un'altra può essere molto più informativa delle due parole singole. Come primo step si parte con il considerare solamente i bigrammi, senza le parole singole. Da qui in poi sarà applicata la rimozione delle stopwords in quanto più sensata e leggermente migliore in termini di risultati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   39.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   40.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   42.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   45.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.9min finished\n"
     ]
    }
   ],
   "source": [
    "features = [15000, 20000, 50000, 100000, None]\n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None,\n",
    "                 ngram_range=(2,2), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Sicuramente i risultati sono scadenti perché la dimensione della lista di features non era adeguata alla numerosità di bigrammi che si sono creati e quindi un gran numero è stato scartato. Come si nota di seguito i livelli di accuratezza sono molto distanti da quelli precedenti, però è anche vero che senza scartare nessun elemento i risultati sono sempre abbastanza mediocri. Questo lascia pensare che indipendentemente dal numero di features considerate, una classificazione con solamente i bigrammi e ignorando le parole singole non è utile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.3687\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.3798\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.4152\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.4401\n",
      "Parametri: {'alpha': 0.1, 'fit_prior': True}\tAccuratezza: 0.4779\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.6 Unigrammi e bigrammi](#3.6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Il passo successivo è quello di considerare sia le parole singole che i bigrammi. L'unione delle informazioni della frequenza dei singoli termini e la combinazione con altre parole dovrebbe dare delle informazioni extra e dunque migliorare il modello con solo le singole parole. In questo caso è stato adeguato il numero di feature da valutare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   58.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "features = [150000, 200000, 350000, 550000, None]\n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None,\n",
    "                 ngram_range=(1,2), verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5927\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5932\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5936\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.593\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.5816\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Dall'output si nota come il miglioramento è evidente: il passaggio da $0.552$ a $0.594$ è in termini assoluti limitato, però considerando che si tratta del modello peggiore, questa soluzione lascia ben sperare per l'applicazione su modelli più performanti. Il numero di features è stato scelto in modo coerente: sia $15000$ che oltre il doppio ottengono gli stessi risultati, mentre senza nessuna limitazione i risultati peggiorano ma sono comunque migliori di qualsiasi altra tecnica provata fino a questo momento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.7 Da unigrammi a trigrammi](#3.7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Andando aventi ulteriormente è possibile aggiungere anche i trigrammi. Non dovrebbero avere un grosso impatto in quanto molti pattern hanno lunghezza contenuta ed alcuni sono formati da due singole parole, però si prova comunque a fare un tentativi. Il numero di features è scalato in proporzione al numero di elementi attesi che saranno individuati. Non viene valutato il modello senza limitazioni in quanto le informazioni non possono essere contenute in solo $32$ GB di memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    8.4s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   14.7s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   21.1s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   33.1s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   45.1s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   58.5s remaining:    5.2s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    7.3s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   14.1s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   34.3s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   47.5s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:  1.0min remaining:    5.5s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    8.2s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   15.8s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   23.4s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   38.3s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   52.9s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:  1.1min remaining:    6.1s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   16.6s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   24.4s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   39.5s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   54.5s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:  1.2min remaining:    6.4s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.3min finished\n"
     ]
    }
   ],
   "source": [
    "features = [500000, 1000000, 2000000, 2500000]\n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=\"english\",\n",
    "                  ngram_range=(1,3), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Non si nota un ulteriore miglioramento. Il modello migliore è quello con più termini ma aggiungerne altri non è possibile per motivi di memoria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5723\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5693\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5762\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5774\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.8 Unione con w2v](#3.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Per questo lavoro è possibile percorrere un'altra strada che è quella di far riferimento ai termini più simili per ciascuna parola più frequente individuandoli tramite il modello w2v addestrato su tutte le recensioni. Questo modello era stato creato per la cluster analisi, da cui si ricavava una matrice di similarità e sulla quale sono state realizzate le tecniche di clustering agglomerativo. Il modello tuttavia non presentava risultati incoraggianti e l'indice si Silhouette era distante dal migliore ottenuto tramite i synset delle tassonomie.\n",
    "<br></br>\n",
    "\n",
    "Il modello viene caricato dovendo specificare anche la classe callback che era stata create nell'altro notebook per visualizzare la funzione di perdita ad ogni iterazione dato che di default la libreria forniva la perdita totale del modello ad una certa epoca e non la differenza fra un epoca e l'altra. Per un bug di gensim non è possibile caricare il modello che ha salvato queste informazioni aggiuntive ed una delle soluzione è richiamare la funzione create e poi successivamente caricare il modello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "class callback(CallbackAny2Vec):\n",
    "    \"\"\"\n",
    "    Callback to print loss after each epoch\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.epoch = 0\n",
    "\n",
    "    def on_epoch_end(self, model):\n",
    "        loss = model.get_latest_training_loss()\n",
    "        if self.epoch == 0:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss))\n",
    "        else:\n",
    "            print('Loss after epoch {}: {}'.format(self.epoch, loss - self.loss_previous_step))\n",
    "        self.epoch += 1\n",
    "        self.loss_previous_step = loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_w2v = Word2Vec.load(\"IMDB_word2vec.model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Dato che l'assegnazione dei label ai diversi pattern è stata effettuata considerando i termini più frequenti e i sinonimi identificati dal synset di WordNet, tutto il dataset deve essere ricaricato e la lista dei sinonimi deve essere estesa con i nuovi termini trovati dal modello w2v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = pd.read_csv('labels_df simplified.csv', delimiter=\";\")\n",
    "labels[\"Synonyms\"] = labels[\"Word\"].map(diz_similarity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "\n",
    "La funzione w2v_most_similar ha il compito di creare una lista dei termini più comuni ad ogni termine più frequente secondo il modello w2v generato e alla cosine similarity. L'unico parametro in ingresso è il numero di termini da considerare in quanto saranno realizzate diverse prove raccogliendo un certo numero di parole più simili. Sinteticamente i passaggi della funzione sono:\n",
    "* Si scorre per ogni parola del dataset (termini più frequenti) e si trovano i top termini più simili. Il risultato è una lista al cui interno ogni elemento è una tupla con parola e valore di cosine similarity.\n",
    "* Per ogni parola in questa lista si controlla se non sia già nel dataset (la metrica di similarità varia dai synset al modello w2v, è quindi possibile che un termine presente in questi sia in realtà già un valore del dataset) e nemmeno nei sinonimi di quella parola.\n",
    "* Se questa parola è nuova viene aggiunta al dizionario insieme alla parola corrispondente e in un altro dizionario anche il valore di similarità. Se la parola invece esiste già nel dizionario si controlla se la similarità è maggiore di quella già salvata.\n",
    "    * In caso affermativo, il dizionario viene aggiornato con la nuova chiave.\n",
    "    * In caso negativo, la parola non è aggiunta la dizionario.\n",
    "    \n",
    "L'output della funzione è un dizionario in cui le chiavi sono i termini nel dataset e i valori una lista di termini più comuni ritrovati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_most_similar(topn):\n",
    "    w2v_diz_sim = {}\n",
    "    diz_max = {}\n",
    "    diz_ok = {}\n",
    "    for i in range(len(labels)):\n",
    "        temp = []\n",
    "        try:\n",
    "            sim = model_w2v.most_similar(labels[\"Word\"].iloc[i], topn=topn)\n",
    "            for j in range(len(sim)):\n",
    "                if sim[j][0].lower() != labels[\"Word\"].iloc[i] and sim[j][0] not in labels[\"Synonyms\"].iloc[i] and \"_\" not in sim[j][0]:\n",
    "                    if sim[j][0].lower() not in diz_ok.keys():\n",
    "                        diz_max[sim[j][0].lower()] = labels[\"Word\"].iloc[i]\n",
    "                        diz_ok[sim[j][0].lower()] = sim[j][1]\n",
    "                        temp.append(sim[j][0].lower())\n",
    "                    else:\n",
    "                        if diz_ok[sim[j][0].lower()] < sim[j][1]:\n",
    "                            diz_ok[sim[j][0].lower()] = sim[j][1]\n",
    "                            diz_max[sim[j][0].lower()] = labels[\"Word\"].iloc[i]\n",
    "                            temp.append(sim[j][0].lower())\n",
    "                        else:\n",
    "                            pass\n",
    "        except KeyError:\n",
    "            pass\n",
    "        w2v_diz_sim[labels[\"Word\"].iloc[i]] = temp\n",
    "        \n",
    "    return (w2v_diz_sim, diz_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Come primo modello si seleziona il numero di elementi di default, $10$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "(w2v_diz_sim, diz_max) = w2v_most_similar(topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Nella funzione w2v_most_similar sono stati creati due dizionari per gestire i casi in cui una parola risultasse molto simile a più termini diversi. Il rischio è che questa parola possa essere associata a due termini che però nella clusterizzazione appartengono a due gruppi differenti. La seguente funzione quindi rimuove tutti i duplicati tenendo solamente il termine riferito alla parola con la similarità migliore.\n",
    "<br></br>\n",
    "\n",
    "Ad esempio la parola <i>year</i> non era presente nel dataset ma è stata trovata dal modello w2v più di una volta e quindi assegnata a più parole. La seguente funzione controlla nei due dizionari creati in precedenza a quali parole è collegata e quali sono i valori di similarità tenendo solo il collegamento con la cosine similarity più alta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in w2v_diz_sim.keys():\n",
    "    new_l = []\n",
    "    for word in w2v_diz_sim[key]:\n",
    "        try:\n",
    "            if diz_max[word] == key:\n",
    "                new_l.append(word)\n",
    "            else:\n",
    "                pass\n",
    "        except KeyError:\n",
    "            pass\n",
    "    w2v_diz_sim[key] = new_l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Visualizzazione del nuovo dataset con la lista di sinonimi che si è allargata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>Label</th>\n",
       "      <th>Freq</th>\n",
       "      <th>Synonyms</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>way</td>\n",
       "      <td>0</td>\n",
       "      <td>68935</td>\n",
       "      <td>[manner, style, fashion, mode, ways, hurry, pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>life</td>\n",
       "      <td>0</td>\n",
       "      <td>61168</td>\n",
       "      <td>[existence]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>thing</td>\n",
       "      <td>0</td>\n",
       "      <td>60468</td>\n",
       "      <td>[what, things, stuff]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>love</td>\n",
       "      <td>0</td>\n",
       "      <td>29193</td>\n",
       "      <td>[loved, loves, hate, loving]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>problem</td>\n",
       "      <td>0</td>\n",
       "      <td>16458</td>\n",
       "      <td>[issue, problems]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word  Label   Freq                                           Synonyms\n",
       "0      way      0  68935  [manner, style, fashion, mode, ways, hurry, pr...\n",
       "1     life      0  61168                                        [existence]\n",
       "2    thing      0  60468                              [what, things, stuff]\n",
       "3     love      0  29193                       [loved, loves, hate, loving]\n",
       "4  problem      0  16458                                  [issue, problems]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in range(len(labels)):\n",
    "    labels[\"Synonyms\"].iloc[i] = labels[\"Synonyms\"].iloc[i] + list(w2v_diz_sim.values())[i]\n",
    "labels.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "A questo punto con il nuovo dataset di devono riassegnare tutte le etichette con tutti gli step relativi. Per evitare di riproporre tutto il codice, le parti del notebook della prima parte sono stati salvati in un file .py che è richiamato di seguito. La funzione cluster_label condensa tutti gli step e restituisce il dataset con pattern e classe. I parametri sono:\n",
    "* w2v: se è zero viene caricato il dataset da zero, in questo caso è già stato fatto. La funzione sarà richiamata in seguito in altre applicazioni dove non è necessario utilizzare il modello w2v, in quei casi sarà necessario richiamare il dataset da zero.\n",
    "* stopw: se è uno, si applica già un filtraggio delle stopwords."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:40<00:00, 7802.15it/s]\n"
     ]
    }
   ],
   "source": [
    "%run -i \"labels.py\"\n",
    "(w2v_labels, test2) = cluster_label(w2v=1, stopw=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Topic</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Amazing chemistry</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>seamless CGI</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>practical effects</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>film a firecracker script a true</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>story pulse pounding soundtrack booming</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149707</td>\n",
       "      <td>girl who spent the entire</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149708</td>\n",
       "      <td>Everyone around her constantly bent</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149709</td>\n",
       "      <td>little snot</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149710</td>\n",
       "      <td>little brat</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14149711</td>\n",
       "      <td>good movie</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14149712 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Topic  Label\n",
       "0                               Amazing chemistry      4\n",
       "1                                    seamless CGI      4\n",
       "2                               practical effects      4\n",
       "3                film a firecracker script a true      4\n",
       "4         story pulse pounding soundtrack booming      4\n",
       "...                                           ...    ...\n",
       "14149707                girl who spent the entire      6\n",
       "14149708      Everyone around her constantly bent     50\n",
       "14149709                              little snot     50\n",
       "14149710                              little brat     50\n",
       "14149711                               good movie     10\n",
       "\n",
       "[14149712 rows x 2 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2v_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Si applica la funzione sw_rem per rimovere le stopword e creare sostituire la nuova lista nel dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = sw_rem(test2)\n",
    "w2v_labels[\"Topic\"] = new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(w2v_labels[\"Topic\"], w2v_labels[\"Label\"], \n",
    "                                                    stratify = w2v_labels[\"Label\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.8.1 Unigrammi e stopwords](#3.8.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Si inizia con una prova sulle singole parole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   45.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   44.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   47.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   46.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   50.6s finished\n"
     ]
    }
   ],
   "source": [
    "features = [10000, 15000, 20000, 50000, None]\n",
    "\n",
    "model = naive_bayes.MultinomialNB()\n",
    "\n",
    "parameters = {\"alpha\":[1e-10, 0.05, 0.1, 0.2, 0.3, 0.5, 0.8, 1], \n",
    "              \"fit_prior\":[True, False]}\n",
    "    \n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "I risultati sono buoni, ma sempre leggermente inferiori a quelli ottenuti in precedenza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5403\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5413\n",
      "Parametri: {'alpha': 0.8, 'fit_prior': True}\tAccuratezza: 0.5404\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5363\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5365\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.8.2 Unigrammi e bigrammi](#3.8.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   57.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   59.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  2.0min finished\n"
     ]
    }
   ],
   "source": [
    "features = [150000, 200000, 350000, 550000, None]\n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None,\n",
    "                  ngram_range=(1,2), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Anche con l'unione di unigrammi e bigrammi non si migliorano le performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5592\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5597\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5556\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5604\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.5555\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.8.3 Unigrammi con numero variabile di termini simili](#3.8.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Le scarse performance possono essere dettate dal numero di termini che sono presi in considerazione come candidati sinonimi. Il seguente blocco di codice replica le analisi precedenti iterando su una lista che definisce il numero di parole da considerare nel modello w2v:\n",
    "* Per ogni numero massimo di parole si carica il dataset di base.\n",
    "* Si applica il modello w2v per trovare un numero massimo di sinonimi, si rimuovono i duplicati e si crea un nuovo dataset senza le stopwords.\n",
    "* Si divide il dataset in train e test e successivamente si itera per il numero di features per creare diversi modelli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:43<00:00, 7572.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 1 termini più simili:\n",
      "Parametri: {'alpha': 1, 'fit_prior': True}\tAccuratezza: 0.5786\n",
      "Parametri: {'alpha': 1, 'fit_prior': True}\tAccuratezza: 0.5784\n",
      "Parametri: {'alpha': 1, 'fit_prior': True}\tAccuratezza: 0.5779\n",
      "Parametri: {'alpha': 1, 'fit_prior': True}\tAccuratezza: 0.5752\n",
      "Parametri: {'alpha': 0.1, 'fit_prior': True}\tAccuratezza: 0.5704\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:34<00:00, 8316.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 2 termini più simili:\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5474\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5473\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5469\n",
      "Parametri: {'alpha': 0.05, 'fit_prior': True}\tAccuratezza: 0.5438\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5516\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:38<00:00, 8002.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 5 termini più simili:\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5452\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5461\n",
      "Parametri: {'alpha': 1, 'fit_prior': True}\tAccuratezza: 0.5456\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5423\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5435\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:41<00:00, 7696.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 20 termini più simili:\n",
      "Parametri: {'alpha': 0.2, 'fit_prior': True}\tAccuratezza: 0.5349\n",
      "Parametri: {'alpha': 0.2, 'fit_prior': True}\tAccuratezza: 0.5358\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5348\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5305\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.528\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_words = [1, 2, 5, 20]\n",
    "features = [10000, 15000, 20000, 50000, None]\n",
    "\n",
    "for top in top_words:\n",
    "    labels = pd.read_csv('labels_df simplified.csv', delimiter=\";\")\n",
    "    labels[\"Synonyms\"] = labels[\"Word\"].map(diz_similarity)\n",
    "    \n",
    "    (w2v_diz_sim, diz_max) = w2v_most_similar(topn=top)\n",
    "    \n",
    "    # rimozione duplicati\n",
    "    for key in w2v_diz_sim.keys():\n",
    "        new_l = []\n",
    "        for word in w2v_diz_sim[key]:\n",
    "            try:\n",
    "                if diz_max[word] == key:\n",
    "                    new_l.append(word)\n",
    "                else:\n",
    "                    pass\n",
    "            except KeyError:\n",
    "                pass\n",
    "        w2v_diz_sim[key] = new_l\n",
    "        \n",
    "    # creazione df\n",
    "    for i in range(len(labels)):\n",
    "        labels[\"Synonyms\"].iloc[i] = labels[\"Synonyms\"].iloc[i] + list(w2v_diz_sim.values())[i]\n",
    "        \n",
    "    # assegnazione etichette\n",
    "    (w2v_labels, test2) = cluster_label(w2v=1, stopw=1)\n",
    "    new_test = sw_rem(test2)\n",
    "    w2v_labels[\"Topic\"] = new_test\n",
    "    \n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(w2v_labels[\"Topic\"], w2v_labels[\"Label\"], \n",
    "                                                    stratify = w2v_labels[\"Label\"], random_state = 0)\n",
    "    \n",
    "    # modelli\n",
    "    score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None, verbose=0)\n",
    "    \n",
    "    print(\"Classificazione con \" + str(top) + \" termini più simili:\")\n",
    "    score(score_list)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Dai risultati di accuracy sembrerebbe che più termini sono presi in considerazione, più le performance del modello calino. Questo potrebbe essere dato dal fatto che queste parole, anche se non così frequenti alcune volte, non sono discriminatorie fra le diverse classi e quindi invece di aiutare il modello, lo mettono in difficoltà."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.8.4 Unigrammi e bigrammi con numero variabile di termini simili](#3.8.4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Si replicano le analisi considerando unigrammi e bigrammi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:30<00:00, 8653.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 1 termini più simili:\n",
      "Parametri: {'alpha': 0.8, 'fit_prior': True}\tAccuratezza: 0.591\n",
      "Parametri: {'alpha': 0.8, 'fit_prior': True}\tAccuratezza: 0.5911\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5907\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5897\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.577\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [02:00<00:00, 6494.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 2 termini più simili:\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5767\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5775\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.578\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5747\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.5691\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:54<00:00, 6850.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 5 termini più simili:\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5663\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5668\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5623\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.567\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.5597\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [02:05<00:00, 6262.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 20 termini più simili:\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5548\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5555\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5562\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5548\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.5535\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "top_words = [1, 2, 5, 20]\n",
    "features = [150000, 200000, 350000, 550000, None]\n",
    "\n",
    "for top in top_words:\n",
    "    labels = pd.read_csv('labels_df simplified.csv', delimiter=\";\")\n",
    "    labels[\"Synonyms\"] = labels[\"Word\"].map(diz_similarity)\n",
    "    \n",
    "    (w2v_diz_sim, diz_max) = w2v_most_similar(topn=top)\n",
    "    \n",
    "    # rimozione duplicati\n",
    "    for key in w2v_diz_sim.keys():\n",
    "        new_l = []\n",
    "        for word in w2v_diz_sim[key]:\n",
    "            try:\n",
    "                if diz_max[word] == key:\n",
    "                    new_l.append(word)\n",
    "                else:\n",
    "                    pass\n",
    "            except KeyError:\n",
    "                pass\n",
    "        w2v_diz_sim[key] = new_l\n",
    "        \n",
    "    # creazione df\n",
    "    for i in range(len(labels)):\n",
    "        labels[\"Synonyms\"].iloc[i] = labels[\"Synonyms\"].iloc[i] + list(w2v_diz_sim.values())[i]\n",
    "        \n",
    "    # assegnazione etichette\n",
    "    (w2v_labels, test2) = cluster_label(w2v=1, stopw=1)\n",
    "    new_test = sw_rem(test2)\n",
    "    w2v_labels[\"Topic\"] = new_test\n",
    "    \n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(w2v_labels[\"Topic\"], w2v_labels[\"Label\"], \n",
    "                                                    stratify = w2v_labels[\"Label\"], random_state = 0)\n",
    "    \n",
    "    # modelli\n",
    "    score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None, \n",
    "                      ngram_range=(1,2), verbose=0)\n",
    "    \n",
    "    print(\"Classificazione con \" + str(top) + \" termini più simili:\")\n",
    "    score(score_list)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Anche in questo caso più parole significano meno accuratezza. Con una sola parola aggiunta le performance sono sempre intorno allo $0.59$ ma con decimali più bassi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.8.5 Unigrammi e bigrammi e livello soglia di similarità](#3.8.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Un'alternativa è quella di non considerare un numero fisso di parole poiché a seconda del termine selezionato i primi termini più simili potrebbero avere valori di similarità molto diversi. La funzione w2v_most_similar2 ricava i $100$ termini più simili per ogni parola, ma considera possibili candidati solamente quelli che hanno una similarità superiore ad una certa soglia. Il resto della funzione lavora nello stesso modo di quella precedente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_most_similar2(sim_value, topn=100):\n",
    "    w2v_diz_sim = {}\n",
    "    diz_max = {}\n",
    "    diz_ok = {}\n",
    "    for i in range(len(labels)):\n",
    "        temp = []\n",
    "        try:\n",
    "            sim = model_w2v.most_similar(labels[\"Word\"].iloc[i], topn=topn)\n",
    "            for j in range(len(sim)):\n",
    "                if sim[j][1] > sim_value:\n",
    "                    if sim[j][0].lower() != labels[\"Word\"].iloc[i] and sim[j][0] not in labels[\"Synonyms\"].iloc[i] and \"_\" not in sim[j][0]:\n",
    "                        if sim[j][0].lower() not in diz_ok.keys():\n",
    "                            diz_max[sim[j][0].lower()] = labels[\"Word\"].iloc[i]\n",
    "                            diz_ok[sim[j][0].lower()] = sim[j][1]\n",
    "                            temp.append(sim[j][0].lower())\n",
    "                        else:\n",
    "                            if diz_ok[sim[j][0].lower()] < sim[j][1]:\n",
    "                                diz_ok[sim[j][0].lower()] = sim[j][1]\n",
    "                                diz_max[sim[j][0].lower()] = labels[\"Word\"].iloc[i]\n",
    "                                temp.append(sim[j][0].lower())\n",
    "                            else:\n",
    "                                pass\n",
    "        except KeyError:\n",
    "            pass\n",
    "        w2v_diz_sim[labels[\"Word\"].iloc[i]] = temp\n",
    "        \n",
    "    return (w2v_diz_sim, diz_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Prima di iterare sulla lista di valori si effettuano delle prove per vedere il numero di sinonimi totali che sarebbero individuati dal modello w2v data una certa soglia. Dall'output della funzione i valori del dizionario sono messi in una lista e successivamente si estraggono con set gli elementi unici."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sim value</th>\n",
       "      <th>Num words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>7163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.5</td>\n",
       "      <td>3478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.6</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.7</td>\n",
       "      <td>162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.8</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sim value  Num words\n",
       "0        0.4       7163\n",
       "1        0.5       3478\n",
       "2        0.6        961\n",
       "3        0.7        162\n",
       "4        0.8         24\n",
       "5        0.9          0"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_sim_value = [0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n",
    "sin_words = []\n",
    "for value in test_sim_value:\n",
    "    (w2v_diz_sim, diz_max) = w2v_most_similar2(sim_value=value)\n",
    "    sin_words.append(len(set(list(deepflatten(list(w2v_diz_sim.values()), depth=1)))))\n",
    "                     \n",
    "test_sim_value_df = pd.DataFrame({\"Sim value\":test_sim_value, \"Num words\":sin_words})\n",
    "test_sim_value_df.head(len(test_sim_value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Come realizzato prima per il numero di parole da considerare, il seguente blocco di codice effettua una doppia iterazione, sia su una lista di valori minimi di similarità necessari per considerare una parola un sinonimo e sul numero di features. In base ai risultati ottenuti in precedenza si selezionano i valori intermedi con l'aggiunta di $0.65$ che potrebbe portare ad un buon trade-off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:32<00:00, 8474.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 0.6 similarità di soglia:\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5725\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5732\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.569\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.574\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.5664\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:58<00:00, 6642.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 0.65 similarità di soglia:\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5771\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5777\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5783\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.575\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.5687\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:43<00:00, 7546.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 0.7 similarità di soglia:\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5848\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5853\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5858\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5853\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.575\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:49<00:00, 7155.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classificazione con 0.8 similarità di soglia:\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5908\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5914\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5918\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5912\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': False}\tAccuratezza: 0.58\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test_sim_value = [0.6, 0.65, 0.7, 0.8]\n",
    "features = [150000, 200000, 350000, 550000, None]\n",
    "\n",
    "for value in test_sim_value:\n",
    "    labels = pd.read_csv('labels_df simplified.csv', delimiter=\";\")\n",
    "    labels[\"Synonyms\"] = labels[\"Word\"].map(diz_similarity)\n",
    "    \n",
    "    (w2v_diz_sim, diz_max) = w2v_most_similar2(sim_value=value)\n",
    "    \n",
    "    # rimozione duplicati\n",
    "    for key in w2v_diz_sim.keys():\n",
    "        new_l = []\n",
    "        for word in w2v_diz_sim[key]:\n",
    "            try:\n",
    "                if diz_max[word] == key:\n",
    "                    new_l.append(word)\n",
    "                else:\n",
    "                    pass\n",
    "            except KeyError:\n",
    "                pass\n",
    "        w2v_diz_sim[key] = new_l\n",
    "        \n",
    "    # creazione df\n",
    "    for i in range(len(labels)):\n",
    "        labels[\"Synonyms\"].iloc[i] = labels[\"Synonyms\"].iloc[i] + list(w2v_diz_sim.values())[i]\n",
    "        \n",
    "    # assegnazione etichette\n",
    "    (w2v_labels, test2) = cluster_label(w2v=1, stopw=1)\n",
    "    new_test = sw_rem(test2)\n",
    "    w2v_labels[\"Topic\"] = new_test\n",
    "    \n",
    "    # split\n",
    "    X_train, X_test, y_train, y_test = train_test_split(w2v_labels[\"Topic\"], w2v_labels[\"Label\"], \n",
    "                                                    stratify = w2v_labels[\"Label\"], random_state = 0)\n",
    "    \n",
    "    # modelli\n",
    "    score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None, \n",
    "                      ngram_range=(1,2), verbose=0)\n",
    "    \n",
    "    print(\"Classificazione con \" + str(value) + \" similarità di soglia:\")\n",
    "    score(score_list)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Anche in questo caso si conferma quello detto in precedenza: più termini non aiutano il modello e man mano che la soglia di similarità aumenta, più salgono le performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.9 Ricampionamento](#3.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Una soluzione molto utilizzata per risolvere i problemi di classi non bilanciate è quella di ricampionare le osservazioni. Queste tecniche si dividono principalmente in oversampling, ovvero ricampionare le osservazioni dalle classi meno numerose e undersampling che ha l'approccio opposto. Anche se il comando \"stratify\" durante lo split fra train e test aiuta a mantenere la stessa proporzione di osservazioni nelle diverse classi fra i due dataset, ed è proprio una alternativa al ricampionamento, si possono ottenere comunque risultati interessanti.\n",
    "<br></br>\n",
    "\n",
    "All'interno di queste due macrocategorie esistono diverse tecniche specifiche, ognuna con una sua particolarità."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.9.1 Random oversampling](#3.9.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La prima tecnica è quella di ricampionare le osservazioni delle classi meno frequenti in modo casuale. Questo metodo non dovrebbe ottenere delle buone performance in quanto è noto in letteratura che si tende ad avere overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pattern_labels\", \"rb\") as read_file:\n",
    "    pattern_labels = pickle.load(read_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test = sw_rem(pattern_labels[\"Topic\"])\n",
    "\n",
    "pattern_labels[\"Topic\"] = new_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Questione molto importante è il momento in cui bisogna effettuare il ricampionamento. Come riportato da [diverse analisi](https://beckernick.github.io/oversampling-modeling/) il ricampionamento deve essere effettuato dopo la divisione fra train e test in modo da evitare che delle osservazioni identiche possano finire in entrambi i dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pattern_labels[\"Topic\"], pattern_labels[\"Label\"], \n",
    "                                                    stratify = pattern_labels[\"Label\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "La funzione grid2 è una variazione della precedente in cui non è compreso lo split del dataset e la creazione dei vettori TF-IDF in quanto questa procedura varia a seconda della strategia di ricampionamento utilizzata. La funzione contiene solamente gli step finali che partono dalla ricerca dei modelli fino al salvataggio dei risultati di accuratezza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid2(xtrain_tfidf, y_train, model, parameters, verbose):\n",
    "    clf = GridSearchCV(model, param_grid=parameters, scoring=\"accuracy\", cv=3, verbose=verbose, n_jobs=5)\n",
    "    clf.fit(xtrain_tfidf, y_train)\n",
    "    y_pred = clf.predict(xtest_tfidf)\n",
    "    score_list.append(clf.best_params_)\n",
    "    score_list.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return (score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "L'installazione della libreria imblearn, deve essere fatta attraverso i privilegi di amministrazione e installerà anche una nuova versione di sklear.utilities.\n",
    "Richiamare la libreria potrebbe chiamare problemi con sklearn per l'import di alcuni moduli, la [soluzione](https://stackoverflow.com/questions/56540967/sklearn-model-selection-error-importerror-cannot-import-name-approximate-mod) è quella di riavviare il kernel.\n",
    "<br></br>\n",
    "   \n",
    "Per l'oversampling casuale è necessario creare un oggetto omonimo alla sua libreria, RandomOverSampler, e selezionare un random seed per replicare i risultati, non sono necessari altri parametri. Applicando la funzione fit_sample a questo oggetto, si creano i vettori di TF-IDF. Da qui in poi saranno utilizzati solamente modelli con unigrammi e bigrammi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "score_list = []\n",
    "features = [150000, 200000, 350000, 550000, None]\n",
    "for feature in features:\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                 stop_words=None, ngram_range=(1,2))\n",
    "    xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "    \n",
    "    ros = RandomOverSampler(random_state=0)\n",
    "    ros_xtrain_tfidf, ros_y_train = ros.fit_sample(xtrain_tfidf, y_train)\n",
    "    \n",
    "    score_list = grid2(model=model, xtrain_tfidf=ros_xtrain_tfidf, y_train=ros_y_train, parameters=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Non si hanno i valori di accuratezza sul train ma quelli sul test indicano che questa tecnica non è adatta al dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 1e-10, 'fit_prior': False}\tAccuratezza: 0.5543\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': False}\tAccuratezza: 0.5535\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': False}\tAccuratezza: 0.5504\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': False}\tAccuratezza: 0.5458\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5035\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.9.2 Random undersampling](#3.9.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:    9.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:    8.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   10.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   10.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   11.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   55.2s finished\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "score_list = []\n",
    "features = [30000, 50000, 100000, 150000, 200000, None]\n",
    "for feature in features:\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                 stop_words=None, ngram_range=(1,2))\n",
    "    xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    rus = RandomUnderSampler(random_state=0, replacement=True)\n",
    "    rus_xtrain_tfidf, rus_y_train = rus.fit_sample(xtrain_tfidf, y_train)\n",
    "    \n",
    "    score_list = grid2(model=model, xtrain_tfidf=rus_xtrain_tfidf, y_train=rus_y_train, parameters=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5457\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5442\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5424\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5413\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5401\n",
      "Parametri: {'alpha': 0.8, 'fit_prior': False}\tAccuratezza: 0.5164\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Le prossime tecniche si basano tutte sulla ricerca di osservazioni chiave che dovranno essere ricampionate, poiché più informative di altre. La selezione di queste viene realizzata tramite una Nearest Neighbour che può richiedere diverso tempo e anche la creazione dei vettori TF-IDF con molte più informazioni rallenta notevolamente i processi.\n",
    "<br></br>\n",
    "\n",
    "Sono state realizzate delle prove con un campione ridotto del dataset e i tempi computazionali crescono in maniera quasi esponenziale all'aumentare delle osservazioni e non è possibile effettuare questi ricampionamenti su tutte le classi. Una alternativa è quindi quella di analizzare i risultati del migliore modello fino ad adesso e vedere se nelle statistiche del report c'è una classe in cui il modello fatica particolarmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=350000, stop_words=None, \n",
    "                             ngram_range=(1,2))\n",
    "xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "xtest_tfidf = tfidf_vect.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.86      0.68    720508\n",
      "           0       0.60      0.46      0.52    343136\n",
      "           4       0.64      0.46      0.53    331548\n",
      "           6       0.59      0.49      0.54    369540\n",
      "           8       0.63      0.45      0.53    296363\n",
      "           9       0.57      0.29      0.39    100668\n",
      "          10       0.60      0.64      0.62    881921\n",
      "          50       0.62      0.49      0.55    416871\n",
      "         100       0.59      0.71      0.64     76873\n",
      "\n",
      "    accuracy                           0.59   3537428\n",
      "   macro avg       0.60      0.54      0.56   3537428\n",
      "weighted avg       0.60      0.59      0.58   3537428\n",
      "\n",
      "[[622682  62431  54839  68669  52402  21071 135947  72378  12739]\n",
      " [  5454 156228  15132  15255  13243   4281  33197  16452    632]\n",
      " [  3538  12845 151658  11752  10685   3269  29976  13857    760]\n",
      " [ 10672  17678  16979 182058  13671   7276  36656  21599   2706]\n",
      " [  4522  11252  10281   8994 134023   3177  28366  12026    313]\n",
      " [   875   2674   2541   3253   2683  29481   6839   3461    178]\n",
      " [ 50895  59781  60534  56012  52352  24636 563239  67550   3662]\n",
      " [  6722  17902  16919  19080  15522   6147  40994 205916   1346]\n",
      " [ 15148   2345   2665   4467   1782   1330   6707   3632  54537]]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NB, WordLevel TF-IDF:  0.5936013397304483\n",
      "Wall time: 12.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "accuracy = train_model(naive_bayes.MultinomialNB(alpha=0.3, fit_prior=True), xtrain_tfidf, y_train, xtest_tfidf, \n",
    "                       \"Naive Bayes\")\n",
    "print (\"NB, WordLevel TF-IDF: \", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Anche se la classe degli attori, l'ultima, è quella meno numerosa, le performance sono accettabili e non le peggiori. La classe numero $9$ ha bassa precisione e bassa recall ed è la candiata per il ricampionamento. Come si evince però da tutti i livelli di precisione, non ci sono delle classi in cui il modello è particolarmente funzionante, ma sono tutte su livelli simili, questo può segnalare che un miglioramento radicale delle performance non sia possibile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{10: 881921,\n",
       " -1: 720508,\n",
       " 50: 416871,\n",
       " 6: 369540,\n",
       " 0: 343136,\n",
       " 4: 331548,\n",
       " 8: 296363,\n",
       " 9: 100668,\n",
       " 100: 76873}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_freq = dict(Counter(y_test).most_common())\n",
    "class_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=3>\n",
    "    \n",
    "Dalle classi del test di estraggono le numerosità."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.9.3 SMOTE oversampling](#3.9.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "score_list = []\n",
    "features = [100000, 150000, 200000, 350000, 550000]\n",
    "for feature in features:\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                 stop_words=None, ngram_range=(1,2))\n",
    "    xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    sm = SMOTE(random_state=0, sampling_strategy={9:class_freq[10]})\n",
    "    sm_xtrain_tfidf, sm_y_train = sm.fit_sample(xtrain_tfidf, y_train)\n",
    "    \n",
    "    score_list = grid2(model=model, xtrain_tfidf=sm_xtrain_tfidf, y_train=sm_y_train, parameters=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5928\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5938\n",
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5943\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5943\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5936\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.4min finished\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "score_list = []\n",
    "features = [200000, 350000]\n",
    "for feature in features:\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                 stop_words=None, ngram_range=(1,2))\n",
    "    xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    sm = SMOTE(random_state=0, k_neighbors=10, sampling_strategy={9:class_freq[10]})\n",
    "    sm_xtrain_tfidf, sm_y_train = sm.fit_sample(xtrain_tfidf, y_train)\n",
    "    \n",
    "    score_list = grid2(model=model, xtrain_tfidf=sm_xtrain_tfidf, y_train=sm_y_train, parameters=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 0.5, 'fit_prior': True}\tAccuratezza: 0.5944\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5943\n"
     ]
    }
   ],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.9.4 ADASYN oversampling](#3.9.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import ADASYN\n",
    "\n",
    "score_list = []\n",
    "features = [200000, 350000]\n",
    "for feature in features:\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                 stop_words=None, ngram_range=(1,2))\n",
    "    xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    ad = ADASYN(random_state=0, sampling_strategy={9:class_freq[10]}, n_jobs=5)\n",
    "    ad_xtrain_tfidf, ad_y_train = ad.fit_sample(xtrain_tfidf, y_train)\n",
    "    \n",
    "    score_list = grid2(model=model, xtrain_tfidf=ad_xtrain_tfidf, y_train=ad_y_train, parameters=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [3.9.6 NearMiss undersampling](#3.9.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:    0.9s finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\base.py\u001b[0m in \u001b[0;36mfit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m     79\u001b[0m         )\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 81\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_resample\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_X_columns\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y_name\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\imblearn\\under_sampling\\_prototype_selection\\_nearmiss.py\u001b[0m in \u001b[0;36m_fit_resample\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    220\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m                     dist_vec, idx_vec = self.nn_.kneighbors(\n\u001b[1;32m--> 222\u001b[1;33m                         \u001b[0mX_class\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_neighbors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    223\u001b[0m                     )\n\u001b[0;32m    224\u001b[0m                     index_target_class = self._selection_dist_based(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    640\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce_func\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreduce_func\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m                 \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0meffective_metric_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 642\u001b[1;33m                 **kwds))\n\u001b[0m\u001b[0;32m    643\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fit_method\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'ball_tree'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'kd_tree'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances_chunked\u001b[1;34m(X, Y, reduce_func, metric, n_jobs, working_memory, **kwds)\u001b[0m\n\u001b[0;32m   1590\u001b[0m             \u001b[0mX_chunk\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1591\u001b[0m         D_chunk = pairwise_distances(X_chunk, Y, metric=metric,\n\u001b[1;32m-> 1592\u001b[1;33m                                      n_jobs=n_jobs, **kwds)\n\u001b[0m\u001b[0;32m   1593\u001b[0m         if ((X is Y or Y is None)\n\u001b[0;32m   1594\u001b[0m                 \u001b[1;32mand\u001b[0m \u001b[0mPAIRWISE_DISTANCE_FUNCTIONS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36mpairwise_distances\u001b[1;34m(X, Y, metric, n_jobs, force_all_finite, **kwds)\u001b[0m\n\u001b[0;32m   1747\u001b[0m         \u001b[0mfunc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetric\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmetric\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1749\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_parallel_pairwise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1750\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1751\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36m_parallel_pairwise\u001b[1;34m(X, Y, func, n_jobs, **kwds)\u001b[0m\n\u001b[0;32m   1346\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1347\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0meffective_n_jobs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1348\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1350\u001b[0m     \u001b[1;31m# enforce a threading backend to prevent data communication overhead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[1;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[0;32m    301\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    302\u001b[0m         \u001b[1;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 303\u001b[1;33m         \u001b[0mdistances\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    304\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.under_sampling import NearMiss\n",
    "\n",
    "score_list = []\n",
    "features = [100000, 150000, 200000, 350000, 550000]\n",
    "for feature in features:\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                 stop_words=None, ngram_range=(1,2))\n",
    "    xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    nm = NearMiss(version=1)\n",
    "    nm_xtrain_tfidf, nm_y_train = nm.fit_sample(xtrain_tfidf, y_train)\n",
    "    \n",
    "    score_list = grid2(model=model, xtrain_tfidf=nm_xtrain_tfidf, y_train=nm_y_train, parameters=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "features = [100000, 150000, 200000, 350000, 550000]\n",
    "for feature in features:\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                 stop_words=None, ngram_range=(1,2))\n",
    "    xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    nm = NearMiss(version=2)\n",
    "    nm_xtrain_tfidf, nm_y_train = nm.fit_sample(xtrain_tfidf, y_train)\n",
    "    \n",
    "    score_list = grid2(model=model, xtrain_tfidf=nm_xtrain_tfidf, y_train=nm_y_train, parameters=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = []\n",
    "features = [100000, 150000, 200000, 350000, 550000]\n",
    "for feature in features:\n",
    "    tfidf_vect = TfidfVectorizer(analyzer=\"word\", token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                 stop_words=None, ngram_range=(1,2))\n",
    "    xtrain_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "    xtest_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "    nm = NearMiss(version=3)\n",
    "    nm_xtrain_tfidf, nm_y_train = nm.fit_sample(xtrain_tfidf, y_train)\n",
    "    \n",
    "    score_list = grid2(model=model, xtrain_tfidf=nm_xtrain_tfidf, y_train=nm_y_train, parameters=parameters, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression()\n",
    "parameters = {\"C\":[0.01, 0.1, 1, 10, 50], \n",
    "              \"solver\":[\"newton-cg\", \"lbfgs\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid(features, model, parameters, analyzer, stop, ngram_range=(1,1), verbose=10):\n",
    "    score_list = []\n",
    "    for feature in features:\n",
    "        tfidf_vect = TfidfVectorizer(analyzer=analyzer, token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                     stop_words=stop, ngram_range=ngram_range)\n",
    "        xtrain_tfidf =  tfidf_vect.fit_transform(X_train)\n",
    "        xtest_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "        clf = GridSearchCV(model, param_grid=parameters, scoring=\"accuracy\", cv=3, verbose=verbose, n_jobs=5)\n",
    "        clf.fit(xtrain_tfidf, y_train)\n",
    "        y_pred = clf.predict(xtest_tfidf)\n",
    "        score_list.append(clf.best_params_)\n",
    "        score_list.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return (score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done  30 out of  30 | elapsed: 1089.1min finished\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-64185c4683b3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mfeatures\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m200000\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m350000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscore_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"word\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-57-62f3428cd2fe>\u001b[0m in \u001b[0;36mgrid\u001b[1;34m(features, model, parameters, analyzer, stop, ngram_range, verbose)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m         \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"accuracy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m         \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtrain_tfidf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxtest_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mscore_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    740\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1599\u001b[0m                       \u001b[0mpenalty\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpenalty\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_squared_sum\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1600\u001b[0m                       sample_weight=sample_weight)\n\u001b[1;32m-> 1601\u001b[1;33m             for class_, warm_start_coef_ in zip(classes_, warm_start_coef))\n\u001b[0m\u001b[0;32m   1602\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1603\u001b[0m         \u001b[0mfold_coefs_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mfold_coefs_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    919\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    920\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 921\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    922\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    923\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[0margs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m             w0, n_iter_i = _newton_cg(hess, func, grad, w0, args=args,\n\u001b[1;32m--> 945\u001b[1;33m                                       maxiter=max_iter, tol=tol)\n\u001b[0m\u001b[0;32m    946\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0msolver\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'liblinear'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m             coef_, intercept_, n_iter_i, = _fit_liblinear(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001b[0m in \u001b[0;36m_newton_cg\u001b[1;34m(grad_hess, func, grad, x0, args, tol, maxiter, maxinner, line_search, warn)\u001b[0m\n\u001b[0;32m    192\u001b[0m         \u001b[1;31m# Inner loop: solve the Newton update by conjugate gradient, to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;31m# avoid inverting the Hessian\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 194\u001b[1;33m         \u001b[0mxsupi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_cg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfhess_p\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmaxinner\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtermcond\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    195\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m         \u001b[0malphak\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\optimize.py\u001b[0m in \u001b[0;36m_cg\u001b[1;34m(fhess_p, fgrad, maxiter, tol)\u001b[0m\n\u001b[0;32m     89\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 91\u001b[1;33m         \u001b[0mAp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfhess_p\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     92\u001b[0m         \u001b[1;31m# check curvature\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         \u001b[0mcurv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpsupi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mhessp\u001b[1;34m(v)\u001b[0m\n\u001b[0;32m    421\u001b[0m         \u001b[0mr_yhat\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[0mhessProd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfit_intercept\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[0mhessProd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mr_yhat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m         \u001b[0mhessProd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m:\u001b[0m\u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mv\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mfit_intercept\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[1;34m(a, b, dense_output)\u001b[0m\n\u001b[0;32m    149\u001b[0m             \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mret\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__rmatmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    568\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    569\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 570\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__rmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    571\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    572\u001b[0m     \u001b[1;31m####################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__rmul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m                 \u001b[0mtr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mtr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m     \u001b[1;31m#####################################\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__mul__\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    473\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_vector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mM\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    474\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mN\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 475\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mul_multivector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    477\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misscalarlike\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\scipy\\sparse\\compressed.py\u001b[0m in \u001b[0;36m_mul_multivector\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    485\u001b[0m         \u001b[0mfn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_sparsetools\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'_matvecs'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m         fn(M, N, n_vecs, self.indptr, self.indices, self.data,\n\u001b[1;32m--> 487\u001b[1;33m            other.ravel(), result.ravel())\n\u001b[0m\u001b[0;32m    488\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "features = [200000, 350000]\n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=None, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.10 Alternative a TF-IDF](#3.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textvec import vectorizers\n",
    "from textvec.vectorizers import (TfBinIcfVectorizer, Tfchi2Vectorizer, TfgrVectorizer, \n",
    "                                 TfIcfVectorizer, TfigVectorizer, TforVectorizer, TfpfVectorizer, \n",
    "                                 TfrfVectorizer, TfrrfVectorizer, SifVectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"pattern_labels\", \"rb\") as read_file:\n",
    "    pattern_labels = pickle.load(read_file)\n",
    "    \n",
    "new_test = sw_rem(pattern_labels[\"Topic\"])\n",
    "pattern_labels[\"Topic\"] = new_test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(pattern_labels[\"Topic\"], pattern_labels[\"Label\"], \n",
    "                                                    stratify = pattern_labels[\"Label\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-39-9918cadae333>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mtfgr_vect\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTfIcfVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"l2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0mxtrain_tfgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfgr_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mxtest_tfgr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfgr_vect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    572\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m             \u001b[1;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 574\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    576\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\textvec\\vectorizers.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, min_freq)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspdiags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mnormalize\u001b[1;34m(X, norm, axis, copy, return_norm)\u001b[0m\n\u001b[0;32m   1703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m     X = check_array(X, sparse_format, copy=copy,\n\u001b[1;32m-> 1705\u001b[1;33m                     estimator='the normalize function', dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m   1706\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    509\u001b[0m                                       \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m                                       \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m                                       accept_large_sparse=accept_large_sparse)\n\u001b[0m\u001b[0;32m    512\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m         \u001b[1;31m# If np.array(..) gives ComplexWarning, then we convert the warning\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_ensure_sparse_format\u001b[1;34m(spmatrix, accept_sparse, dtype, copy, force_all_finite, accept_large_sparse)\u001b[0m\n\u001b[0;32m    336\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m             _assert_all_finite(spmatrix.data,\n\u001b[1;32m--> 338\u001b[1;33m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[0m\u001b[0;32m    339\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    340\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mspmatrix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m     58\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     59\u001b[0m                     (type_err,\n\u001b[1;32m---> 60\u001b[1;33m                      msg_dtype if msg_dtype is not None else X.dtype)\n\u001b[0m\u001b[0;32m     61\u001b[0m             )\n\u001b[0;32m     62\u001b[0m     \u001b[1;31m# for object dtype data, we only check for NaNs (GH-13254)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "score_list = []\n",
    "features = [200000, 350000]\n",
    "\n",
    "for feature in features:\n",
    "    cv = CountVectorizer()\n",
    "    cv_train = cv.fit_transform(X_train)\n",
    "    cv_test = cv.transform(X_test)\n",
    "    \n",
    "    tfgr_vect = vectorizers.TfIcfVectorizer(norm=\"l2\")\n",
    "    xtrain_tfgr = tfgr_vect.fit_transform(cv_train, y_train)\n",
    "    xtest_tfgr = tfgr_vect.transform(cv_test)\n",
    "    \n",
    "    clf = GridSearchCV(model, param_grid=parameters, scoring=\"accuracy\", cv=3, verbose=verbose, n_jobs=5)\n",
    "    clf.fit(xtrain_tfgr, y_train)\n",
    "    y_pred = clf.predict(xtest_tfgr)\n",
    "    score_list.append(clf.best_params_)\n",
    "    score_list.append(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid3(features, model, parameters, analyzer, stop, ngram_range=(1,1), vectorizer, verbose=10):\n",
    "    score_list = []\n",
    "    for feature in features:\n",
    "        tfidf_vect = TfidfVectorizer(analyzer=analyzer, token_pattern=r'\\w{1,}', max_features=feature, \n",
    "                                     stop_words=stop, ngram_range=ngram_range)\n",
    "        xtrain_tfidf =  tfidf_vect.fit_transform(X_train)\n",
    "        xtest_tfidf =  tfidf_vect.transform(X_test)\n",
    "\n",
    "        clf = GridSearchCV(model, param_grid=parameters, scoring=\"accuracy\", cv=3, verbose=verbose, n_jobs=5)\n",
    "        clf.fit(xtrain_tfidf, y_train)\n",
    "        y_pred = clf.predict(xtest_tfidf)\n",
    "        score_list.append(clf.best_params_)\n",
    "        score_list.append(accuracy_score(y_test, y_pred))\n",
    "    \n",
    "    return (score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.5 Unione classi nomi attori e attori](#3.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_label = list(pattern_labels[\"Label\"])\n",
    "new_label = []\n",
    "for el in temp_label:\n",
    "    if el == 100:\n",
    "        el = 6\n",
    "    new_label.append(el)\n",
    "    \n",
    "pattern_labels[\"Label\"] = new_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(pattern_labels[\"Topic\"], pattern_labels[\"Label\"], \n",
    "                                                    stratify = pattern_labels[\"Label\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    8.9s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   13.5s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   21.5s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   29.7s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   38.3s remaining:    3.4s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   41.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    4.8s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    9.1s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   13.7s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   22.2s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   39.8s remaining:    3.5s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   43.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    4.6s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    8.8s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   13.6s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   30.3s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   39.5s remaining:    3.5s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   42.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    4.7s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    9.0s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   13.4s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   21.9s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   30.4s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   39.4s remaining:    3.5s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   43.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.0s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:    9.6s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   14.3s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   23.3s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   32.9s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   42.5s remaining:    3.8s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   46.1s finished\n"
     ]
    }
   ],
   "source": [
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5515\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5484\n",
      "Parametri: {'alpha': 0.8, 'fit_prior': True}\tAccuratezza: 0.548\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5477\n",
      "Parametri: {'alpha': 0.3, 'fit_prior': True}\tAccuratezza: 0.5454\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(score_list):\n",
    "    print(\"Parametri: \" + str(score_list[i]) + \"\\tAccuratezza: \" + str(round(score_list[i+1], 4)))\n",
    "    i += 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "## [3.6 Label originali](#3.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████| 784259/784259 [01:31<00:00, 8540.19it/s]\n"
     ]
    }
   ],
   "source": [
    "original_labels = cluster_label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(original_labels[\"Topic\"], original_labels[\"Label\"], \n",
    "                                                    stratify = original_labels[\"Label\"], random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    6.8s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   12.1s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   17.7s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   28.3s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   38.5s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   49.7s remaining:    4.4s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   53.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.6s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   10.8s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   16.3s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   26.5s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   36.9s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   47.5s remaining:    4.2s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   51.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   11.0s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   27.2s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   37.3s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   48.7s remaining:    4.3s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   53.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   10.9s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   16.5s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   26.6s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   36.8s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   47.8s remaining:    4.3s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   52.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.7s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   16.9s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   27.0s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   37.5s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   48.2s remaining:    4.3s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   52.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    5.8s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   11.2s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   16.8s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   27.1s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   37.7s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   48.7s remaining:    4.3s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   53.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   12.3s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   18.4s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   30.0s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   41.5s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   53.8s remaining:    4.8s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:   58.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=5)]: Using backend LokyBackend with 5 concurrent workers.\n",
      "[Parallel(n_jobs=5)]: Done   3 tasks      | elapsed:    6.4s\n",
      "[Parallel(n_jobs=5)]: Done   8 tasks      | elapsed:   12.5s\n",
      "[Parallel(n_jobs=5)]: Done  15 tasks      | elapsed:   19.3s\n",
      "[Parallel(n_jobs=5)]: Done  22 tasks      | elapsed:   30.8s\n",
      "[Parallel(n_jobs=5)]: Done  31 tasks      | elapsed:   43.1s\n",
      "[Parallel(n_jobs=5)]: Done  44 out of  48 | elapsed:   56.0s remaining:    5.0s\n",
      "[Parallel(n_jobs=5)]: Done  48 out of  48 | elapsed:  1.0min finished\n"
     ]
    }
   ],
   "source": [
    "features = [1000, 3000, 5000, 10000, 15000, 20000, 50000, None]\n",
    "score_list = grid(features=features, model=model, parameters=parameters, analyzer=\"word\", stop=\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.4955\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5289\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5317\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5325\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5325\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5323\n",
      "Parametri: {'alpha': 1e-10, 'fit_prior': True}\tAccuratezza: 0.5308\n",
      "Parametri: {'alpha': 1, 'fit_prior': False}\tAccuratezza: 0.5208\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "while i < len(score_list):\n",
    "    print(\"Parametri: \" + str(score_list[i]) + \"\\tAccuratezza: \" + str(round(score_list[i+1], 4)))\n",
    "    i += 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
